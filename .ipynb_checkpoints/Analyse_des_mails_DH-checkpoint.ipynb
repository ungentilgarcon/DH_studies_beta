{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some imports\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from difflib import SequenceMatcher\n",
    "import re,os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FOR TOPIC MODELLING\n",
    "#https://de.dariah.eu/tatom/topic_model_python.html\n",
    "import numpy as np  # a conventional alias\n",
    "\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_detection_with_pyenchant(string_to_read):\n",
    "    #https://stackoverflow.com/questions/3788870/how-to-check-if-a-word-is-an-english-word-with-python\n",
    "    import enchant\n",
    "    lg_ang=0\n",
    "    us = enchant.Dict(\"en_US\")\n",
    "    #print \"US LOADED\"\n",
    "    fr = enchant.Dict(\"fr_FR\")\n",
    "    #print \"FR LOADED\"\n",
    "    lg_fr=0\n",
    "    lg_ang=0\n",
    "    #print \"string_to_read\",string_to_read\n",
    "    for word in string_to_read.split():\n",
    "        #print fr.check(word)\n",
    "        #print word\n",
    "        if fr.check(word) == True:\n",
    "            lg_fr+=1\n",
    "        if us.check(word) == True:\n",
    "            lg_ang+=1\n",
    "    #print \"THERE I AM\"\n",
    "    if lg_fr >= lg_ang :\n",
    "        return \"french\"\n",
    "    else:\n",
    "        if lg_ang > lg_fr :\n",
    "        \n",
    "            return \"english\"\n",
    "        else: \n",
    "            return \"NEITHER ENGLISH NOR FRENCH\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_analysis_with_mallet(string_to_read):\n",
    "    lng = language_detection_with_pyenchant(string_to_read)\n",
    "    if lng== \"french\" :\n",
    "        lng= [\"a\",\"à\",\"â\",\"abord\",\"afin\",\"ah\",\"ai\",\"aie\",\"ainsi\",\"allaient\",\"allo\",\"allô\",\"allons\",\"après\",\"assez\",\"attendu\",\"au\",\"aucun\",\"aucune\",\"aujourd\",\"aujourd'hui\",\"auquel\",\"aura\",\"auront\",\"aussi\",\"autre\",\"autres\",\"aux\",\"auxquelles\",\"auxquels\",\"avaient\",\"avais\",\"avait\",\"avant\",\"avec\",\"avoir\",\"ayant\",\"b\",\"bah\",\"beaucoup\",\"bien\",\"bigre\",\"boum\",\"bravo\",\"brrr\",\"c\",\"ça\",\"car\",\"ce\",\"ceci\",\"cela\",\"celle\",\"celle-ci\",\"celle-là\",\"celles\",\"celles-ci\",\"celles-là\",\"celui\",\"celui-ci\",\"celui-là\",\"cent\",\"cependant\",\"certain\",\"certaine\",\"certaines\",\"certains\",\"certes\",\"ces\",\"cet\",\"cette\",\"ceux\",\"ceux-ci\",\"ceuxlà\",\"chacun\",\"chaque\",\"cher\",\"chère\",\"chères\",\"chers\",\"chez\",\"chiche\",\"chut\",\"ci\",\"cinq\",\"cinquantaine\",\"cinquante\",\"cinquantième\",\"cinquième\",\"clac\",\"clic\",\"combien\",\"comme\",\"comment\",\"compris\",\"concernant\",\"contre\",\"couic\",\"crac\",\"d\",\"da\",\"dans\",\"de\",\"debout\",\"dedans\",\"dehors\",\"delà\",\"depuis\",\"derrière\",\"des\",\"dès\",\"désormais\",\"desquelles\",\"desquels\",\"dessous\",\"dessus\",\"deux\",\"deuxième\",\"deuxièmement\",\"devant\",\"devers\",\"devra\",\"différent\",\"différente\",\"différentes\",\"différents\",\"dire\",\"divers\",\"diverse\",\"diverses\",\"dix\",\"dix-huit\",\"dixième\",\"dix-neuf\",\"dixsept\",\"doit\",\"doivent\",\"donc\",\"dont\",\"douze\",\"douzième\",\"dring\",\"du\",\"duquel\",\"durant\",\"e\",\"effet\",\"eh\",\"elle\",\"elle-même\",\"elles\",\"ellesmêmes\",\"en\",\"encore\",\"entre\",\"envers\",\"environ\",\"es\",\"ès\",\"est\",\"et\",\"etant\",\"étaient\",\"étais\",\"était\",\"étant\",\"etc\",\"été\",\"etre\",\"être\",\"eu\",\"euh\",\"eux\",\"eux-mêmes\",\"excepté\",\"f\",\"façon\",\"fais\",\"faisaient\",\"faisant\",\"fait\",\"feront\",\"fi\",\"flac\",\"floc\",\"font\",\"g\",\"gens\",\"h\",\"ha\",\"hé\",\"hein\",\"hélas\",\"hem\",\"hep\",\"hi\",\"ho\",\"holà\",\"hop\",\"hormis\",\"hors\",\"hou\",\"houp\",\"hue\",\"hui\",\"huit\",\"huitième\",\"hum\",\"hurrah\",\"i\",\"il\",\"ils\",\"importe\",\"j\",\"je\",\"jusqu\",\"jusque\",\"k\",\"l\",\"la\",\"là\",\"laquelle\",\"las\",\"le\",\"lequel\",\"les\",\"lès\",\"lesquelles\",\"lesquels\",\"leur\",\"leurs\",\"longtemps\",\"lorsque\",\"lui\",\"lui-même\",\"m\",\"ma\",\"maint\",\"mais\",\"malgré\",\"me\",\"même\",\"mêmes\",\"merci\",\"mes\",\"mien\",\"mienne\",\"miennes\",\"miens\",\"mille\",\"mince\",\"moi\",\"moi-même\",\"moins\",\"mon\",\"moyennant\",\"n\",\"na\",\"ne\",\"néanmoins\",\"neuf\",\"neuvième\",\"ni\",\"nombreuses\",\"nombreux\",\"non\",\"nos\",\"notre\",\"nôtre\",\"nôtres\",\"nous\",\"nous-mêmes\",\"nul\",\"o\",\"o|\",\"ô\",\"oh\",\"ohé\",\"olé\",\"ollé\",\"on\",\"ont\",\"onze\",\"onzième\",\"ore\",\"ou\",\"où\",\"ouf\",\"ouias\",\"oust\",\"ouste\",\"outre\",\"p\",\"paf\",\"pan\",\"par\",\"parmi\",\"partant\",\"particulier\",\"particulière\",\"particulièrement\",\"pas\",\"passé\",\"pendant\",\"personne\",\"peu\",\"peut\",\"peuvent\",\"peux\",\"pff\",\"pfft\",\"pfut\",\"pif\",\"plein\",\"plouf\",\"plus\",\"plusieurs\",\"plutôt\",\"pouah\",\"pour\",\"pourquoi\",\"premier\",\"première\",\"premièrement\",\"près\",\"proche\",\"psitt\",\"puisque\",\"q\",\"qu\",\"quand\",\"quant\",\"quanta\",\"quant-à-soi\",\"quarante\",\"quatorze\",\"quatre\",\"quatre- vingt\",\"quatrième\",\"quatrièmement\",\"que\",\"quel\",\"quelconque\",\"quelle\",\"quelles\",\"quelque\",\"quelques\",\"quelqu'un\",\"quels\",\"qui\",\"quiconque\",\"quinze\",\"quoi\",\"quoique\",\"r\",\"revoici\",\"revoilà\",\"rien\",\"s\",\"sa\",\"sacrebleu\",\"sans\",\"sapristi\",\"sauf\",\"se\",\"seize\",\"selon\",\"sept\",\"septième\",\"sera\",\"seront\",\"ses\",\"si\",\"sien\",\"sienne\",\"siennes\",\"siens\",\"sinon\",\"six\",\"sixième\",\"soi\",\"soi-même\",\"soit\",\"soixante\",\"son\",\"sont\",\"sous\",\"stop\",\"suis\",\"suivant\",\"sur\",\"surtout\",\"t\",\"ta\",\"tac\",\"tant\",\"te\",\"té\",\"tel\",\"telle\",\"tellement\",\"telles\",\"tels\",\"tenant\",\"tes\",\"tic\",\"tien\",\"tienne\",\"tiennes\",\"tiens\",\"toc\",\"toi\",\"toi-même\",\"ton\",\"touchant\",\"toujours\",\"tous\",\"tout\",\"toute\",\"toutes\",\"treize\",\"trente\",\"très\",\"trois\",\"troisième\",\"troisièmement\",\"trop\",\"tsoin\",\"tsouin\",\"tu\",\"u\",\"un\",\"une\",\"unes\",\"uns\",\"v\",\"va\",\"vais\",\"vas\",\"vé\",\"vers\",\"via\",\"vif\",\"vifs\",\"vingt\",\"vivat\",\"vive\",\"vives\",\"vlan\",\"voici\",\"voilà\",\"vont\",\"vos\",\"votre\",\"vôtre\",\"vôtres\",\"vous\",\"vous-mêmes\",\"vu\",\"w\",\"x\",\"y\",\"z\",\"zut\"]\n",
    "    \n",
    "    vectorizer = text.CountVectorizer(input=string_to_read, stop_words=lng, min_df=3)\n",
    "    dtm = vectorizer.fit_transform(string_to_read.split()).toarray()\n",
    "    vocab = np.array(vectorizer.get_feature_names())\n",
    "    dtm.shape\n",
    "    len(vocab)\n",
    "    num_topics = 20\n",
    "    num_top_words = 20\n",
    "    clf = decomposition.NMF(n_components=num_topics, random_state=1)\n",
    "    doctopic = clf.fit_transform(dtm)\n",
    "    topic_words = []\n",
    "    for topic in clf.components_:\n",
    "        word_idx = np.argsort(topic)[::-1][0:num_top_words]\n",
    "        topic_words.append([vocab[i] for i in word_idx])\n",
    "    doctopic = doctopic / np.sum(doctopic, axis=1, keepdims=True)\n",
    "    return [topic_words,doctopic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so far french support\n",
    "def find_geo_topics(string_to_read, lng):\n",
    "    geo=0\n",
    "    geo_words=[]\n",
    "    #print string_to_read\n",
    "    if lng== \"french\":\n",
    "        for word in (string_to_read.split()):\n",
    "        #print word\n",
    "        #LUSSAULT ;) https://www.espacestemps.net/articles/entrees-par-categories/\n",
    "            # if (word in [\"Théorie de l’espace\",\"Accessibilité\",\"Acteur spatial\",\"Action spatiale\",\"Agencement\",\"Agglomération\",\"Ailleurs\",\"Aire\",\"Aire culturelle\",\"Alignement\",\"Ambiance architecturale et urbaine\",\"Aménagement du territoire\",\"Anamorphose\",\"Anthropisation\",\"Archipel mégalopolitain mondial \",\"Armature urbaine\",\"Attraction\",\"Autocorrélation spatiale\",\"Banlieue\",\"Campagne\",\"Capital spatial\",\"Carte\",\"Carte mentale\",\"Centralité\",\"Centre/Périphérie\",\"Centre urbain\",\"Chorème\",\"Chorotype\",\"Circulation\",\"Citadinité\",\"Communication territoriale\",\"Commutateur\",\"Compromis territorial\",\"Concentration\",\"Configuration spatiale\",\"Confins\",\"Connexité\",\"Contact\",\"Contiguïté\",\"Continent\",\"Continuité\",\"Coprésence\",\"Corps\",\"Cospatialité\",\"Cyberespace\",\"Décentralisation\",\"Découpage\",\"Découverte\",\"Défrichement\",\"Densité\",\"Désert\",\"Déterritorialisation\",\"Développement local\",\"Diaspora\",\"Différenciation spatiale -Diffusion\",\"Discontinuité\",\"Dispositif spatial légitime\",\"Distance\",\"Distribution rang/taille\",\"Distribution spatiale\",\"District industriel\",\"Diversité\",\"Dynamique spatiale\",\"Écart\",\"Échelle\",\"Économie-monde\",\"Écoumène\",\"Edge City\",\"Emblème territorial\",\"Emboîtement\",\"Empire\",\"Enclavement -Ensemble géographique\",\"Espace\",\"Espace public \",\"Espace vécu\",\"État\",\"État local\",\"Étendue\",\"Fédéralisme\",\"Finage\",\"Firme transnationale\",\"Fleuve\",\"Flux\",\"Foncier\",\"Forêt\",\"Fractale\",\"Friche\",\"Front\",\"Front pionnier\",\"Frontière\",\"Générique \",\"Gentrification\",\"Géoéconomie\",\"Géogramme\",\"Géographicité\",\"Géographie\",\"Géon\",\"Géopolitique\",\"Géosystème\",\"Géotype\",\"Ghetto\",\"Glacis\",\"Gouvernement urbain\",\"Gradient\",\"Graphe\",\"Graphique\",\"Gravitaire \",\"Guerre\",\"Habitat\",\"Habitat non-réglementaire\",\"Habiter\",\"Haut lieu\",\"Heimat\",\"Hétérotopie\",\"Hinterland\",\"Horizont\",\"Hors-sol\",\"Hub\",\"Identité spatiale\",\"Île\",\"Image\",\"Imaginaire géographique\",\"Immanence/Transcendance \",\"Infra-urbain\",\"Interaction spatiale\",\"Interface\",\"Interspatialité\",\"Irrigation\",\"Isolat\",\"Isotropie\",\"Jardin\",\"Justice spatiale\",\"Lieu\",\"Lieux centraux \",\"Limite\",\"Littoral\",\"Local\",\"Localisation\",\"Logistique\",\"Maillage\",\"Maison\",\"Marchandise\",\"Médiance\",\"Méditerranée\",\"Mer\",\"Métaphore spatiale\",\"Métrique\",\"Métropole/Mégalopole\",\"Métropolisation\",\"Migration\",\"Milieu\",\"Milieu innovateur\",\"Minorité territoriale\",\"Mobilité\",\"Monde\",\"Mondialisation\",\"Montagne\",\"Nation\",\"Network\",\"Nœud\",\"Norme\",\"Oasis\",\"Objet géographique\",\"Parc à thème\",\"Parc naturel\",\"Parcours\",\"Partie du monde\",\"Pavillonnaire \",\"Pays\",\"Paysage\",\"Périurbain\",\"Peuplement\",\"Polarisation\",\"Population \",\"Position\",\"Pratique spatiale\",\"Projet urbain\",\"Prospective territoriale\",\"Proxémie\",\"Reconstruction\",\"Reconversion\",\"Rénovation/Restauration/Réhabilitation\",\"Représentation de l’espace\",\"Réseau\",\"Réseau technique\",\"Réseau urbain\",\"Rhizome\",\"Rue\",\"Rural\",\"Schéma d’aménagement\",\"Ségrégation\",\"Seuil\",\"Site\",\"Situation géographique\",\"Société-Monde\",\"Sol\",\"Spatialité\",\"Stratégie spatiale\",\"Substance\",\"Système d’Information Géographique \",\"Système productif local \",\"Système spatial\",\"Technopôle/Technopole\",\"Télé-communication\",\"Télétravail\",\"Terre\",\"Territoire\",\"Territorial \",\"Territorialité\",\"Terroir\",\"Topogenèse\",\"Topographie\",\"Topologie\",\"Toponymie\",\"Tourisme\",\"Transition démographique\",\"Transports\",\"Ubiquité\",\"Urbain\",\"Urbain \",\"Urbanisation\",\"Urbanité\",\"Valeur spatiale\",\"Vaterland\",\"Végétation\",\"Village\",\"Ville\",\"Ville mondiale\",\"Ville nouvelle\",\"Violence\",\"Visibilité \",\"Voisinage\",\"Zonage\",\"Zone climatique\"]) or  \"géogr\" in word or \"géomat\" in word :\n",
    "            if  \"géogr\" in word.lower() or \"géomat\" in word.lower() or \"spatial\" in word.lower() or \"urbanis\" in word.lower():  #or \"carto\" in word:  \n",
    "                geo+=1\n",
    "                geo_words.append(word.lower())\n",
    "    if lng== \"english\":\n",
    "        for word in (string_to_read.split()):\n",
    "        #print word\n",
    "        #LUSSAULT ;) https://www.espacestemps.net/articles/entrees-par-categories/\n",
    "             if  \"geogr\" in word.lower() or \"geomat\" in word.lower() or \"spatial\" in word.lower() or \"urbanis\" in word.lower(): # or \"carto\" in word:\n",
    "                geo+=1\n",
    "                geo_words.append(word.lower())\n",
    "    #print \"SUJETS\\n\",geo_words,\"\\n points : \",geo\n",
    "    return [geo, geo_words]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_analysis_with_manual_detection(string_to_read):\n",
    "    lng = language_detection_with_pyenchant(string_to_read)\n",
    "    if lng== \"french\" :\n",
    "        geopoints= find_geo_topics(string_to_read, \"french\")\n",
    "        #print string_to_read\n",
    "    else:\n",
    "        if lng== \"english\" :\n",
    "            geopoints= find_geo_topics(string_to_read, \"english\")\n",
    "        \n",
    "        else:\n",
    "            print \"LANGUAGE NOT YET SUPPORTED\"\n",
    "            geopoints=['',''] \n",
    "    #    lng= [\"a\",\"à\",\"â\",\"abord\",\"afin\",\"ah\",\"ai\",\"aie\",\"ainsi\",\"allaient\",\"allo\",\"allô\",\"allons\",\"après\",\"assez\",\"attendu\",\"au\",\"aucun\",\"aucune\",\"aujourd\",\"aujourd'hui\",\"auquel\",\"aura\",\"auront\",\"aussi\",\"autre\",\"autres\",\"aux\",\"auxquelles\",\"auxquels\",\"avaient\",\"avais\",\"avait\",\"avant\",\"avec\",\"avoir\",\"ayant\",\"b\",\"bah\",\"beaucoup\",\"bien\",\"bigre\",\"boum\",\"bravo\",\"brrr\",\"c\",\"ça\",\"car\",\"ce\",\"ceci\",\"cela\",\"celle\",\"celle-ci\",\"celle-là\",\"celles\",\"celles-ci\",\"celles-là\",\"celui\",\"celui-ci\",\"celui-là\",\"cent\",\"cependant\",\"certain\",\"certaine\",\"certaines\",\"certains\",\"certes\",\"ces\",\"cet\",\"cette\",\"ceux\",\"ceux-ci\",\"ceuxlà\",\"chacun\",\"chaque\",\"cher\",\"chère\",\"chères\",\"chers\",\"chez\",\"chiche\",\"chut\",\"ci\",\"cinq\",\"cinquantaine\",\"cinquante\",\"cinquantième\",\"cinquième\",\"clac\",\"clic\",\"combien\",\"comme\",\"comment\",\"compris\",\"concernant\",\"contre\",\"couic\",\"crac\",\"d\",\"da\",\"dans\",\"de\",\"debout\",\"dedans\",\"dehors\",\"delà\",\"depuis\",\"derrière\",\"des\",\"dès\",\"désormais\",\"desquelles\",\"desquels\",\"dessous\",\"dessus\",\"deux\",\"deuxième\",\"deuxièmement\",\"devant\",\"devers\",\"devra\",\"différent\",\"différente\",\"différentes\",\"différents\",\"dire\",\"divers\",\"diverse\",\"diverses\",\"dix\",\"dix-huit\",\"dixième\",\"dix-neuf\",\"dixsept\",\"doit\",\"doivent\",\"donc\",\"dont\",\"douze\",\"douzième\",\"dring\",\"du\",\"duquel\",\"durant\",\"e\",\"effet\",\"eh\",\"elle\",\"elle-même\",\"elles\",\"ellesmêmes\",\"en\",\"encore\",\"entre\",\"envers\",\"environ\",\"es\",\"ès\",\"est\",\"et\",\"etant\",\"étaient\",\"étais\",\"était\",\"étant\",\"etc\",\"été\",\"etre\",\"être\",\"eu\",\"euh\",\"eux\",\"eux-mêmes\",\"excepté\",\"f\",\"façon\",\"fais\",\"faisaient\",\"faisant\",\"fait\",\"feront\",\"fi\",\"flac\",\"floc\",\"font\",\"g\",\"gens\",\"h\",\"ha\",\"hé\",\"hein\",\"hélas\",\"hem\",\"hep\",\"hi\",\"ho\",\"holà\",\"hop\",\"hormis\",\"hors\",\"hou\",\"houp\",\"hue\",\"hui\",\"huit\",\"huitième\",\"hum\",\"hurrah\",\"i\",\"il\",\"ils\",\"importe\",\"j\",\"je\",\"jusqu\",\"jusque\",\"k\",\"l\",\"la\",\"là\",\"laquelle\",\"las\",\"le\",\"lequel\",\"les\",\"lès\",\"lesquelles\",\"lesquels\",\"leur\",\"leurs\",\"longtemps\",\"lorsque\",\"lui\",\"lui-même\",\"m\",\"ma\",\"maint\",\"mais\",\"malgré\",\"me\",\"même\",\"mêmes\",\"merci\",\"mes\",\"mien\",\"mienne\",\"miennes\",\"miens\",\"mille\",\"mince\",\"moi\",\"moi-même\",\"moins\",\"mon\",\"moyennant\",\"n\",\"na\",\"ne\",\"néanmoins\",\"neuf\",\"neuvième\",\"ni\",\"nombreuses\",\"nombreux\",\"non\",\"nos\",\"notre\",\"nôtre\",\"nôtres\",\"nous\",\"nous-mêmes\",\"nul\",\"o\",\"o|\",\"ô\",\"oh\",\"ohé\",\"olé\",\"ollé\",\"on\",\"ont\",\"onze\",\"onzième\",\"ore\",\"ou\",\"où\",\"ouf\",\"ouias\",\"oust\",\"ouste\",\"outre\",\"p\",\"paf\",\"pan\",\"par\",\"parmi\",\"partant\",\"particulier\",\"particulière\",\"particulièrement\",\"pas\",\"passé\",\"pendant\",\"personne\",\"peu\",\"peut\",\"peuvent\",\"peux\",\"pff\",\"pfft\",\"pfut\",\"pif\",\"plein\",\"plouf\",\"plus\",\"plusieurs\",\"plutôt\",\"pouah\",\"pour\",\"pourquoi\",\"premier\",\"première\",\"premièrement\",\"près\",\"proche\",\"psitt\",\"puisque\",\"q\",\"qu\",\"quand\",\"quant\",\"quanta\",\"quant-à-soi\",\"quarante\",\"quatorze\",\"quatre\",\"quatre- vingt\",\"quatrième\",\"quatrièmement\",\"que\",\"quel\",\"quelconque\",\"quelle\",\"quelles\",\"quelque\",\"quelques\",\"quelqu'un\",\"quels\",\"qui\",\"quiconque\",\"quinze\",\"quoi\",\"quoique\",\"r\",\"revoici\",\"revoilà\",\"rien\",\"s\",\"sa\",\"sacrebleu\",\"sans\",\"sapristi\",\"sauf\",\"se\",\"seize\",\"selon\",\"sept\",\"septième\",\"sera\",\"seront\",\"ses\",\"si\",\"sien\",\"sienne\",\"siennes\",\"siens\",\"sinon\",\"six\",\"sixième\",\"soi\",\"soi-même\",\"soit\",\"soixante\",\"son\",\"sont\",\"sous\",\"stop\",\"suis\",\"suivant\",\"sur\",\"surtout\",\"t\",\"ta\",\"tac\",\"tant\",\"te\",\"té\",\"tel\",\"telle\",\"tellement\",\"telles\",\"tels\",\"tenant\",\"tes\",\"tic\",\"tien\",\"tienne\",\"tiennes\",\"tiens\",\"toc\",\"toi\",\"toi-même\",\"ton\",\"touchant\",\"toujours\",\"tous\",\"tout\",\"toute\",\"toutes\",\"treize\",\"trente\",\"très\",\"trois\",\"troisième\",\"troisièmement\",\"trop\",\"tsoin\",\"tsouin\",\"tu\",\"u\",\"un\",\"une\",\"unes\",\"uns\",\"v\",\"va\",\"vais\",\"vas\",\"vé\",\"vers\",\"via\",\"vif\",\"vifs\",\"vingt\",\"vivat\",\"vive\",\"vives\",\"vlan\",\"voici\",\"voilà\",\"vont\",\"vos\",\"votre\",\"vôtre\",\"vôtres\",\"vous\",\"vous-mêmes\",\"vu\",\"w\",\"x\",\"y\",\"z\",\"zut\"]\n",
    "    \n",
    "    return geopoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_html_pages_in_dirs_and_extract_mails_dict(pages_dir):\n",
    "    list_all_mails=[]\n",
    "    dict_mails={}\n",
    "    #rootdir=\"./DHFR_sample/\"\n",
    "    count_Cc=0\n",
    "    count_message=0\n",
    "    for subdir, dirs, files in os.walk(pages_dir):\n",
    "#ON VA LIRE TOUS LES FICHIERS DU REP ROOTDIR\n",
    "        \n",
    "        for file in files:\n",
    "    #V1     if file.endswith('.html') == True  and file != (\"index.html\") and not re.match(\"mail\\d+.html\",file) : \n",
    "           if re.match(\"msg\\d+.html\",file) :\n",
    "          \n",
    "            # les index.html sont des recap, on pourrait les compter pour s'assurer du nombre de messages\n",
    "                \n",
    "                #!print \"\\n\",os.path.join(subdir, file), \"\\n\"\n",
    "                champs_mail={}\n",
    "                filename=os.path.join(subdir, file)\n",
    "                champs_mail[\"Geo_Topic\"]=read_html_and_testtextextract(filename)\n",
    "                \n",
    "                \n",
    "                soup=BeautifulSoup(open(filename, 'r').read(),'lxml')#, 'html.parser') \n",
    "#RECUPERER LE SUJET DU MESSAGE\n",
    "                \n",
    "                i=0\n",
    "                for zone_cible in soup.findAll('ul'):\n",
    "                    i+=1\n",
    "                    sujet_messg = zone_cible.find(string=re.compile(\"\\[DH\\]\"))\n",
    "                    \n",
    "                    zone_de_metadonnees = None\n",
    "                    special_auteur=0\n",
    "##ON ISOLE LE CHAMPS AUTEUR\n",
    "                    if '<li><strong>From</strong>:' in str(zone_cible) and '<li><strong>To</strong>:' in str(zone_cible) :\n",
    "                        #print \"FROM/TO DETECTED, i= \",i\n",
    "                        count_message+=1\n",
    "                        #print  zone_cible\n",
    "                        nom_auteur= re.sub(r'<ul>\\n<li><strong>From</strong>: ', '',str(zone_cible))\n",
    "                        sep = \"&lt;\"\n",
    "                        nom_auteur = nom_auteur.split(sep, 1)[0].lower()\n",
    "                        \n",
    "                        \n",
    "                        mail1= re.sub(r'<ul>\\n<li><strong>From</strong>:.+\\n.+\\n.+\\n document\\.write\\(\\\"', '',str(zone_cible))\n",
    "                        mail2=re.sub(r'<ul>\\n<li><strong>From</strong>:.+\\n.+\\n.+\\n document\\.write\\(\\\".+@\\\" \\+ \\\"', '',str(zone_cible))\n",
    "                        sep1 = \"\\\" + \\\"@\\\" + \"\n",
    "                        sep2 = \"\\\")\"\n",
    "                        mail1= mail1.split(sep1, 1)[0]\n",
    "                        mail2= mail2.split(sep2, 1)[0]\n",
    "                        mail_auteur= mail1+\"@\"+mail2\n",
    "                        mail_auteur=mail_auteur.lower()\n",
    "                        #print mail_auteur\n",
    "                        if len(mail_auteur)>60:\n",
    "                            try:\n",
    "                                mail= re.sub(r'<ul>\\n<li><strong>From</strong>:', '',str(zone_cible))\n",
    "                                mail=re.search('&lt;(.*)&gt;',str(mail))\n",
    "                                mail=mail.group(1)\n",
    "                                #print \"MAILBIS\",mail\n",
    "                                mail_auteur=mail.lower()\n",
    "                                #special_auteur=1\n",
    "                            except:\n",
    "                                print \"BUG\"\n",
    "                        #CHECK PROPER CAPTURE OF THE NAME    \n",
    "                        if len(nom_auteur)>50:\n",
    "                            #print zone_cible\n",
    "                            nom_auteur=mail_auteur\n",
    "                        if len(nom_auteur)<5:\n",
    "                            nom_auteur=mail_auteur\n",
    "                        if nom_auteur[0]== \"\\\"\":\n",
    "                            nom_auteur=nom_auteur[1:]\n",
    "                            nom_auteur=nom_auteur[:-2]\n",
    "                            print nom_auteur\n",
    "                        if nom_auteur.endswith(' '):\n",
    "                            nom_auteur=nom_auteur[:-1]\n",
    "                        if  mail_auteur not in list_all_mails:\n",
    "                            list_all_mails.append(mail_auteur)\n",
    "                            \n",
    "                        #!print \"nom_auteur \",nom_auteur+\" mail_auteur \"+mail_auteur,\"\\n\"\n",
    "                        champs_mail[\"nom_auteur\"]=  nom_auteur.lower()\n",
    "                        champs_mail[\"mail_auteur\"]=  mail_auteur.lower()\n",
    "                        champs_mail[\"ref_physique_de_l_article\"]=  os.path.join(subdir, file)\n",
    "                        if sujet_messg is not None:\n",
    "                            champs_mail[\"sujet_du_message\"] = sujet_messg.lower()\n",
    "##ON ISOLE LE CHAMP DESTINATAIRES\n",
    "                        #if special_auteur == 1:\n",
    "                            #print \"ZCspecAut\",zone_cible\n",
    "                        #else: \n",
    "                        \n",
    "                        destinataires=re.sub(r'<ul>\\n<li><strong>From</strong>:.+\\n.+\\n.+\\n.+\\n.+\\n.+\\n.+\\n', '',str(zone_cible))\n",
    "                        \n",
    "                        sep3=\";</li>\"\n",
    "                        destinataires= destinataires.split(sep3, 1)[0]\n",
    "                        #print destinataires\n",
    "                        dest=re.findall(\"<script type=.*\\n.+\\n.+\\n.+\\n.+/script>\", destinataires)\n",
    "                        #print dest\n",
    "                        liste_destinataires=[]\n",
    "                        for destinataire in dest:\n",
    "                            #print destinataire,\"\\n___________________\\n\"\n",
    "                            mail1= re.sub(r'<script type=\\\"text/javascript\\\">\\n <!-- \\n document\\.write\\(\\\"', '',str(destinataire))\n",
    "                            mail2=re.sub(r'<script type=\\\"text/javascript\\\">\\n <!-- \\n document\\.write\\(\\\".+@\\\" \\+ \\\"', '',str(destinataire))\n",
    "                            sep1 = \"\\\" + \\\"@\\\" + \"\n",
    "                            sep2 = \"\\\")\"\n",
    "                            mail1= mail1.split(sep1, 1)[0].lower()\n",
    "                            mail2= mail2.split(sep2, 1)[0].lower()\n",
    "                            mail_destinataire= mail1+\"@\"+mail2\n",
    "                            #print mail_destinataire,\"\\n___________\\n\"\n",
    "                            if mail_destinataire not in liste_destinataires :\n",
    "                                liste_destinataires.append(mail_destinataire)\n",
    "                            if  mail_destinataire not in list_all_mails:\n",
    "                                list_all_mails.append(mail_destinataire)\n",
    "                        if liste_destinataires==[]:\n",
    "                            #print zone_cible\n",
    "                            liste_destinataires=['dh@groupes.renater.fr']\n",
    "                        #!print \"destinataires: \",liste_destinataires,\"\\n\"\n",
    "                        champs_mail[\"liste_mails_dests\"] = liste_destinataires\n",
    "                       \n",
    "                        if '<li><strong>Cc</strong>:' in str(zone_cible):\n",
    "##ON ISOLE LE CHAMP CC\n",
    "                            #print \"CC DETECTED, i= \",i\n",
    "                            #print zone_cible\n",
    "                            count_Cc+=1\n",
    "                            CCfield= re.search('<li><strong>Cc</strong>:(.*)<li><strong>Subject</strong>',str(zone_cible),flags=re.DOTALL)\n",
    "                            CC= CCfield.group(1)\n",
    "                            CC=str(CC)\n",
    "                            CC=re.sub(r'^.+\\n','',str(CC),flags=0)\n",
    "                            CCs=re.findall(\"<script type=.*\\n.+\\n.+\\n.+\\n.+/script>\", CC)\n",
    "                            #sep1 = \"\\\" + \\\"@\\\" + \"\n",
    "                            #mail1= mail1.split(sep1, 1)[0]\n",
    "                            #print \"CC FIELd\\n\"#,CCs\n",
    "                            liste_CCs=[]\n",
    "                            for CC in CCs:\n",
    "                                #print CC,\"\\n___________________\\n\"\n",
    "                                mail1= re.sub(r'<script type=\\\"text/javascript\\\">\\n <!-- \\n document\\.write\\(\\\"', '',str(CC))\n",
    "                                mail2=re.sub(r'<script type=\\\"text/javascript\\\">\\n <!-- \\n document\\.write\\(\\\".+@\\\" \\+ \\\"', '',str(CC))\n",
    "                                sep1 = \"\\\" + \\\"@\\\" + \"\n",
    "                                sep2 = \"\\\")\"\n",
    "                                mail1= mail1.split(sep1, 1)[0].lower()\n",
    "                                mail2= mail2.split(sep2, 1)[0].lower()\n",
    "                                mail_CC= mail1+\"@\"+mail2\n",
    "                                #print mail_CC,\"\\n___________\\n\"\n",
    "                                if mail_CC not in liste_CCs :\n",
    "                                    liste_CCs.append(mail_CC.lower())\n",
    "                                if  mail_CC not in list_all_mails:\n",
    "                                    list_all_mails.append(mail_CC.lower())\n",
    "                                \n",
    "                            #!print \"CCs: \",liste_CCs\n",
    "                            champs_mail[\"liste_CCs\"] = liste_CCs\n",
    "##ON ISOLE LE CHAMP DATE                       \n",
    "                        #print \"ZONECIBLE\",zone_cible\n",
    "                        champs_datef=re.search('<li><strong>Date</strong>:(.+?)</li>',str(zone_cible),flags=re.DOTALL)\n",
    "                        #print \"CHAMPSDATEF\",champs_datef\n",
    "                        try :\n",
    "                            champs_date=champs_datef.group(1)\n",
    "                        except :\n",
    "                            #print \"ZCparent\", zone_cible.parent\n",
    "                            champs_date=re.search('<!--X-Date: (.*) -->',str(soup))\n",
    "                            champs_date=champs_date.group(1)\n",
    "                            #print champs_date\n",
    "                            \n",
    "                        #print champs_date\n",
    "                        try : \n",
    "                            champs_date=parser.parse(champs_date)\n",
    "                        except ValueError :\n",
    "                            sep=\" (\"\n",
    "                            champs_date=champs_date.split(sep, 1)[0]\n",
    "                            \n",
    "                        #!print  champs_date\n",
    "                        champs_mail[\"date\"] = champs_date\n",
    "                        \n",
    "                        \n",
    "                        dict_mails[os.path.join(subdir, file)]= champs_mail\n",
    "                        break\n",
    "##LE DICTIONNAIRE DES MAILS SE NOMME dict_mails\n",
    "    #print dict_mails\n",
    "    print count_message,\" messages\"\n",
    "    print count_Cc, \" messages avec Cc\"\n",
    "    ratiocount = float(count_Cc)/float(count_message)\n",
    "    print \"Taux_de_mails_avec_CC:\",ratiocount,\"\\n\"\n",
    "    return [dict_mails,list_all_mails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_and_extract_topo_network(corpus):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_and_extract_topo_Geo_network(corpus):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_and_extract_mails(corpus):\n",
    "    liste_mails=[]\n",
    "    for mesg in corpus:\n",
    "        #print corpus[mesg]\n",
    "        if corpus[mesg]['mail_auteur'].lower() not in liste_mails:\n",
    "            liste_mails.append(corpus[mesg]['mail_auteur'].lower())\n",
    "        for i,key in enumerate(corpus[mesg]['liste_mails_dests']):\n",
    "            #print key\n",
    "            if key.lower() not in liste_mails:\n",
    "                liste_mails.append(key.lower())\n",
    "        if 'liste_CCs' in corpus[mesg] :\n",
    "            #print \"TRUVE CC\"\n",
    "            for i,key in enumerate(corpus[mesg]['liste_CCs']):\n",
    "                #print key\n",
    "                if key.lower() not in liste_mails:\n",
    "                    liste_mails.append(key.lower())\n",
    "    return liste_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_and_extract_localisations(corpus):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_pages_in_dirs_and_testtextextract(pages_dir):\n",
    "    dict_mails={}\n",
    "    #rootdir=\"./DHFR_sample/\"\n",
    "\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(pages_dir):\n",
    "#ON VA LIRE TOUS LES FICHIERS DU REP ROOTDIR\n",
    "        \n",
    "        for file in files:\n",
    "            dictT={}\n",
    "    #V1     if file.endswith('.html') == True  and file != (\"index.html\") and not re.match(\"mail\\d+.html\",file) : \n",
    "            if re.match(\"msg\\d+.html\",file):\n",
    "                filename=os.path.join(subdir, file)\n",
    "                with open(filename, 'r') as myfile:           \n",
    "                \n",
    "                    data=myfile.read()\n",
    "                    result = re.search('<!--X-Body-of-Message-->(.*)<!--X-Body-of-Message-End-->', data, flags=re.DOTALL)\n",
    "                    ZC= result.group(1)\n",
    "                    ZC=cleanhtml(ZC)\n",
    "                    dictT[\"content\"]=ZC.lower()\n",
    "                    dictT[\"geo\"]=topic_analysis_with_manual_detection(ZC)\n",
    "                dict_mails[filename]= dictT\n",
    "            \n",
    "    return dict_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_and_testtextextract(filename):\n",
    "                dictT={}\n",
    "                with open(filename, 'r') as myfile:\n",
    "                    data=myfile.read()\n",
    "                    result = re.search('<!--X-Body-of-Message-->(.*)<!--X-Body-of-Message-End-->', data, flags=re.DOTALL)\n",
    "                    ZC= result.group(1)\n",
    "                    ZC=cleanhtml(ZC)\n",
    "                    dictT[\"content\"]=ZC.lower()\n",
    "                    dictT[\"geo\"]=topic_analysis_with_manual_detection(ZC)\n",
    "                return dictT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_and_extract_names(corpus):\n",
    "    liste_noms=[]\n",
    "    duplicate_list_noms=[]\n",
    "    for mesg in corpus:\n",
    "        try: \n",
    "            if corpus[mesg]['nom_auteur'][0]== \"\\\"\":\n",
    "                print corpus[mesg]['nom_auteur']\n",
    "                \n",
    "        except IndexError:\n",
    "            print \"Bug\", corpus[mesg]['nom_auteur']\n",
    "            print corpus[mesg]\n",
    "            \n",
    "        if [corpus[mesg]['nom_auteur'].lower(),corpus[mesg]['mail_auteur'].lower()] not in liste_noms:\n",
    "            for i,key in enumerate(liste_noms):\n",
    "                if SequenceMatcher(None, corpus[mesg]['nom_auteur'], key[0]).ratio() >=0.9:\n",
    "                    print \"POSSIBLE DUPLICATE |\", corpus[mesg]['nom_auteur'],\"|   |\",key[0],\"|\"\n",
    "                    print corpus[mesg]['mail_auteur'], key[1]\n",
    "                    if [[corpus[mesg]['nom_auteur'].lower(),corpus[mesg]['mail_auteur'].lower()],[key[0],key[1]]] not in duplicate_list_noms:\n",
    "                        [x.lower() for x in corpus[mesg]['nom_auteur']]\n",
    "                        [y.lower() for y in corpus[mesg]['mail_auteur']]\n",
    "                        duplicate_list_noms.append([[corpus[mesg]['nom_auteur'],corpus[mesg]['mail_auteur']],[key[0],key[1]]])\n",
    "                    \n",
    "                \n",
    "            liste_noms.append([corpus[mesg]['nom_auteur'],corpus[mesg]['mail_auteur']])\n",
    "    \n",
    "    return [liste_noms,duplicate_list_noms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aude.da-cruz-lima\n",
      "noiret, serge\n",
      "noiret, serge\n",
      "wandl-vogt, eveline\n",
      "wandl-vogt, eveline\n",
      "elisabeth.belmas\n",
      "viera rebolledo-dhuin\n",
      "ghislain sillaume\n",
      "noiret, serge\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-6c5e5acaee97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_mails_DH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_html_pages_in_dirs_and_extract_mails_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./DHFRsample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print corpus_mails_DH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mliste_de_tous_les_mails\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_mails_DH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpus_mails_DH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_mails_DH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-54476270987a>\u001b[0m in \u001b[0;36mread_html_pages_in_dirs_and_extract_mails_dict\u001b[0;34m(pages_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mchamps_mail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mchamps_mail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Geo_Topic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_html_and_testtextextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-93fea0a5facd>\u001b[0m in \u001b[0;36mread_html_and_testtextextract\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mZC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcleanhtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mdictT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mdictT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic_analysis_with_manual_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdictT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-17f38cdcf1c9>\u001b[0m in \u001b[0;36mtopic_analysis_with_manual_detection\u001b[0;34m(string_to_read)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtopic_analysis_with_manual_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_to_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_detection_with_pyenchant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_to_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlng\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"french\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgeopoints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfind_geo_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_to_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"french\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print string_to_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-b937435e5497>\u001b[0m in \u001b[0;36mlanguage_detection_with_pyenchant\u001b[0;34m(string_to_read)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menchant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_US\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print \"US LOADED\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menchant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fr_FR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print \"FR LOADED\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlg_fr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab/miniconda2/lib/python2.7/site-packages/enchant/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag, broker)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# Now let the superclass initialise the C-library object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0m_EnchantObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab/miniconda2/lib/python2.7/site-packages/enchant/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m#  to create a dummy default broker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_e\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab/miniconda2/lib/python2.7/site-packages/enchant/__init__.pyc\u001b[0m in \u001b[0;36m_init_this\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_this\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_dict_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab/miniconda2/lib/python2.7/site-packages/enchant/__init__.pyc\u001b[0m in \u001b[0;36m_request_dict_data\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnchantStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mnew_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_this\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0meStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Dictionary for language '%s' could not be found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus_mails_DH=read_html_pages_in_dirs_and_extract_mails_dict(\"./DHFRsample\")\n",
    "#print corpus_mails_DH\n",
    "liste_de_tous_les_mails=corpus_mails_DH[1]\n",
    "corpus_mails_DH=corpus_mails_DH[0]\n",
    "\n",
    "\n",
    "\n",
    "liste_mails=read_corpus_and_extract_mails(corpus_mails_DH)\n",
    "print len(liste_mails)\n",
    "print liste_mails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "['mehdi.khamassi@upmc.fr', 'dh@cru.fr', 'isabelle.thiebau@univ-lille2.fr', 'dh@groupes.renater.fr', 'colette.cadiou@irstea.fr', 'claire.clivaz@sib.swiss', 'johann.holland@campus-condorcet.fr', 'christine.michel@insa-lyon.fr', 'cerisier@univ-poitiers.fr', 'marjorie.burghart@ehess.fr', 'tei-fr@cru.fr', 'stephane.loret@univ-nantes.fr', 'quanti@groupes.renater.fr', 'rbdd@services.cnrs.fr', 'stephane.pouyllau@huma-num.fr', 'formation.continue@enc-sorbonne.fr', 'elenagonzalezblanco@yahoo.es', 'humanist@lists.digitalhumanities.org', 'globaloutlookdh-l@uleth.ca', 'digitalclassicist@jiscmail.ac.uk', 'dm-l@uleth.ca', 'dhd@mailman.rrz.uni-hamburg.de', 'aiucd-l@humnet.unipi.it', 'air-l@aoir.org', 'institute@lists.uvic.ca', 'tei-l@listserv.brown.edu', 'humanist-l@uleth.ca', 'centernet@lists.digitalhumanities.org', 'dhcarolina@listserv.unc.edu', 'humanidadesdigitais@gmail.com', 'website@hastac.org', 'southasia-dh@lists.globaloutlookdh.org', 'air-l@listserv.aoir.org', 'humanisticadh@gmail.com', 'caroline.muller@univ-reims.fr', 'ncasanova@mmsh.univ-aix.fr', 'elinaleblanc3007@gmail.com', 'frederic.clavert@unil.ch', 'julia.bonaccorsi@univ-lyon2.fr', 'gerald.kembellec@lecnam.net', 'martin.grandjean@unil.ch', 'richard.walter@ens.fr', 'laurent.romary@inria.fr', 'sarah.cadorel@sciencespo.fr', 'aurelien.berra@gmail.com', 'antoine.courtin@mac.com', 'm.bourgatte@icp.fr', 'aude.da-cruz-lima@mae.u-paris10.fr', 'archives-son-audiovisuel@groups.openedition.org', 'fatihaidmhand@yahoo.es', 'emilien.ruiz@ehess.fr', 'marin.dacos@openedition.org', 'enrico.natale@infoclio.ch', 'aamonnz@gmail.com', 'frederic@clavert.net', 'slh@ens-lyon.fr', 'dominique.stutzmann@irht.cnrs.fr', 'anne-laure.brisac@inha.fr', 'jf.omhover@histographe.com', 'stefanev@club-internet.fr', 'marin.dacos@revues.org', 'serge.noiret@eui.eu', 'marionlame@gmail.com', 'maud.ingarao@ens-lyon.fr', 'schassan@hab.de', 'c.schoech@gmail.com', 'laetitia.bontemps@univ-tours.fr', 'jouni.tuominen@helsinki.fi', 'nicolas.larrousse@huma-num.fr', 'clarisse_bardiot@mac.com', 'vial.stephane@gmail.com', 'benoit.epron@enssib.fr', 'secardinolivier@yahoo.fr', 'adherents-aipu-fr@groupes.renater.fr', 'afec-info@groupes.renater.fr', 'anstia-adherents@groupes.renater.fr', 'debuter-en-dh@groupes.renater.fr', 'emploi-fle@groupes.renater.fr', 'delegue.general@adbu.fr', 'helene.coste@univ-lehavre.fr', 'valerie.neouze@parisdescartes.fr', 'beauguittelaurent@hotmail.com', 'geotamtam@unil.ch', 'martaseve@gmail.com', 'eric.kergosien@univ-lille3.fr', 'liste-egc@polytech.univ-nantes.fr', 'info-ic@listes.irisa.fr', 'magis@imag.fr', 'bull-i3@irit.fr', 'ln@cines.fr', 'liste-proml@lri.fr', 'docs-ri@yahoogroupes.fr', 'marie-laure.massot@ens.fr', 'gpansu@gmail.com', 'francois.theron@uvsq.fr', 'humanum-diffusion@listes.huma-num.fr', 'humanum-veille@listes.huma-num.fr', 'eveline.wandl-vogt@oeaw.ac.at', 'ahdig@googlegroups.com', 'textualscholarship@jiscmail.ac.uk', 'francoise.paquienseguy@sciencespo-lyon.fr', 'vanessa.juloux@ephe.sorbonne.fr', 'ontologie-patrimoine@services.cnrs.fr', 'marta.materni@gmail.com', 'inforsid@listes.insa-lyon.fr', 'jea.herzog@gmail.com', 'florent.laroche@ec-nantes.fr', 'camillemonnier33@hotmail.com', 'guillaume.blum@design.ulaval.ca', 'daniel.stoekl@ephe.sorbonne.fr', 'nicolasthelyrennes2@gmail.com', 'pabloruizfabo@gmail.com', 'alexandre.hocquet@univ-lorraine.fr', 'stamkou@free.fr', 'nadine.dardenne@cnrs.fr', 'jerome.valluy@univ-paris1.fr', 'mkoenig@dhi-paris.fr', 'exploreat@oeaw.ac.at', 'myriam.tazi@sciencespo.fr', 'remi.jimenes@gmail.com', 'jbcamps@hotmail.com', 'thibault.clerice@enc-sorbonne.fr', 'sabine.loudcher@univ-lyon2.fr', 'sarah.cordonnier@gmail.com', 'yosra.ghliss17@gmail.com', 'caroline.rossi@univ-grenoble-alpes.fr', 'jorge.fins@univ-tours.fr', 'huyghe.marie@gmail.com', 'laurent.cailly@univ-tours.fr', 'carmen.brando@gmail.com', 'francesca.frontini@univ-montp3.fr', 'dumouchelsuzanne@yahoo.fr', 'legram@yahoogroupes.fr', 'culture.numerique@ml.free.fr', 'eric.guichard@enssib.fr', 'francoise.blum@univ-paris1.fr', 'beatrice.markhoff@univ-tours.fr', 'antonio.casilli@googlemail.com', 'sylvain.laube@univ-brest.fr', 'elisabeth.belmas@wanadoo.fr', 'projet.iglouvre@gmail.com', 'lisette.calderan@inria.fr', 'claire.clivaz@unil.ch', 'viera.rebolledodhuin@free.fr', 'michel.bernard@univ-paris3.fr', 'aurelie.olivesi@wanadoo.fr', 'diffusion@listes.ancmsp.com', 'efigies-info@rezo.net', 'etudesfeministes-l@simone.univ-tlse2.fr', 'aurelie.olivesi@univ-lyon1.fr', 'cecile.soudan@ehess.fr', 'e.salvatori@mediev.unipi.it', 'gregory.grefenstette@inria.fr', 'emmanuelguez@yahoo.fr', 'cecile.boulaire@univ-tours.fr', 'tei-fr@groupes.renater.fr', 'christine.benevent@univ-tours.fr', 'laurent.gerbier@univ-tours.fr', 'sandrine.breuil@univ-tours.fr', 'michaelesinatra@gmail.com', 'ottaviano.nancy@gmail.com', 'cynthia.pedroja@meshs.fr', 'iglouvremb@gmail.com', 'espejosuros.javier@gmail.com', 'pierre.mounier@openedition.org', 'antoine.blanchard@gmail.com', 'nicole.dufournaud@laposte.net', 'jean-daniel.fekete@inria.fr', 'listes@ahicf.com', 'oledeuff@gmail.com', 'paul.girard@sciencespo.fr', 'mahe.annaig@wanadoo.fr', 'stephane.pouyllau@cnrs.fr', 'nicolas.thely@univ-rennes2.fr', 'ghislain.sillaume@cvce.eu', 'pierre.mounier@ehess.fr', 'nicolas.legrand@obspm.fr', 'alexandre.moatti@mines.org', 'svhoolan@ulb.ac.be', 'marie.e.lescasse@gmail.com', 'histoire_eco-request@groupes.renater.fr', 'athena@services.cnrs.fr', 'archives-fr@yahoogroupes.fr', 'nep-his@lists.repec.org', 'medici@listes.huma-num.fr', 'ferinterfrance@googlegroups.com', 'gerald.kembellec@cnam.fr', 'judith.hannoun@univ-amu.fr', 'francesco.beretta@ish-lyon.cnrs.fr', 'claire.lemercier@sciencespo.fr', 'laurence.rageot@univ-tours.fr', 'inatheque@ina.fr', 'frederic.clavert@uni.lu', 'joel.marchand@huma-num.fr', 'raphaelle.krummeich@univ-rouen.fr', 'stephane.lamasse@univ-paris1.fr', 'anne.baillot@gmail.com', 'delphine.cavallo@univ-amu.fr', 'adbs-info@listes.adbs.fr', 'accesouvert@groupes.renater.fr', 'doccitanist@services.cnrs.fr', 'info-aria@lsis.org', 'florence.andreacola@univ-grenoble-alpes.fr', 'elodie.faath@openedition.org', 'francois.bavaud@unil.ch', 'llist@unil.ch', 'amelie.vairelles@sciencespo.fr', 'recherche.coordination@bnf.fr', 'dh-request@groupes.renater.fr', 'adeline.joffres@huma-num.fr', 'recherche-design@listes.univ-paris1.fr', 'projekt-membres@liste.unimes.fr', 'projekt@unimes.fr', 'info@design-fax.fr', 'theuth@listes.univ-rennes1.fr', 'antonio.casilli@ehess.fr', 'graham.ranger@univ-avignon.fr', 'corpora@uib.no', 'saes@univ-pau.fr', 'alaes_liste@yahoogroupes.fr', 'parislinguists@yahoogroupes.fr', 'agorantic@listes.univ-avignon.fr', 'pascal.cristofoli@ehess.fr', 'raphaelle.bour@irit.fr', 'annael.le-poullennec@psl.eu', 'irihs@univ-rouen.fr', 'olfa.lamloum@gmail.com', 'pierazzo@gmail.com', 'clemence.jacquot@gmail.com', 'sclerisse@parisnanterre.fr', 'listesocius@groups.openedition.org', 'digit_hum@ens.fr', 'florence.clavaud@free.fr', 'amel.fraisse@univ-lille3.fr', 'jouni.tuominen@aalto.fi', 'georges-xavier.blary@unilim.fr', 'rene.audet@lit.ulaval.ca', 'jakob.epler@dariah.eu', 'jerome.darmont@univ-lyon2.fr', 'madics-adoc@listes.univ-lyon2.fr', 'annonces@madics.fr', 'fil-tmd@groupes.renater.fr', 'eda-liste@listes.univ-lyon2.fr', 'gazettebd3@imag.fr', 'thierry.poibeau@ens.fr', 'dbernhard@unistra.fr', 'sandrine.clerisse@cnrs.fr', 'txm-users@groupes.renater.fr', 'litor@listes.univ-paris3.fr', 'numeruniv-quotidien@cines.fr', 'caroline.cance@univ-orleans.fr', 'gresillon@cmb.hu-berlin.de', 'cecile.rodrigues@cnrs.fr', 'jahjah.marc@gmail.com', 'muriel.foulonneau@gmail.com', 'arno.zucker@gmail.com', 'yamina.bensaadoune@univ-rouen.fr', 'aurelie.olivesi@gmail.com', 'pe.barrault@gmail.com', 'emmanuelle.duwez@sciencespo.fr', 'manuel.zacklad@cnam.fr', 'mathieu.andro@versailles.inra.fr', 'lisa.chupin@gmail.com', 'corpus-ecrits@cru.fr', 'marie-noelle.polino@ahicf.com', 'clarisse_bardiot@me.com', 'christine.chadier@univ-lyon3.fr', 'valerie.beaugiraud@ens-lyon.fr', 'laurens@ehess.fr', 'iwetel@listserv.rediris.es', 'infoling@listserv.rediris.es', 'redhd@humanidadesdigitales.net', 'spadinielena@gmail.com', 'hdefouca@u-paris10.fr', 'olivier.marlet@univ-tours.fr', 'emmanuelle.morlock@gmail.com', 'cahier@groupes.renater.fr', 'audrey.baneyx@sciencespo.fr']\n"
     ]
    }
   ],
   "source": [
    "print len(liste_de_tous_les_mails)\n",
    "print liste_de_tous_les_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(5000000)\n",
    "\n",
    "with open('liste_de_tous_les_mails.obj', 'wb') as handle:\n",
    "    pickle.dump(liste_de_tous_les_mails, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('liste_de_tous_les_mails.obj', 'rb') as handle:\n",
    "    liste_de_tous_les_mails = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(5000000)\n",
    "\n",
    "with open('corpus_mails_DH.obj', 'wb') as handle:\n",
    "    pickle.dump(corpus_mails_DH, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('corpus_mails_DH.obj', 'rb') as handle:\n",
    "    corpus_mails_DH = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_txt=read_html_pages_in_dirs_and_testtextextract(\"./DHFRsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print #corpus_txt\n",
    "#lng= language_detection_with_pyenchant(str(corpus_txt))\n",
    "#print lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSSIBLE DUPLICATE | pierre mounier |   | pierre mounier |\n",
      "pierre.mounier@openedition.org pierre.mounier@ehess.fr\n",
      "POSSIBLE DUPLICATE | clarisse bardiot |   | clarisse bardiot |\n",
      "clarisse_bardiot@me.com clarisse_bardiot@mac.com\n",
      "POSSIBLE DUPLICATE | claire clivaz |   | claire clivaz |\n",
      "claire.clivaz@sib.swiss claire.clivaz@unil.ch\n",
      "POSSIBLE DUPLICATE | frédéric clavert |   | frédéric clavert |\n",
      "frederic.clavert@uni.lu frederic@clavert.net\n",
      "POSSIBLE DUPLICATE | stéphane pouyllau |   | stéphane pouyllau |\n",
      "stephane.pouyllau@cnrs.fr stephane.pouyllau@huma-num.fr\n",
      "POSSIBLE DUPLICATE | marin dacos |   | marin dacos |\n",
      "marin.dacos@openedition.org marin.dacos@revues.org\n",
      "POSSIBLE DUPLICATE | antonio casilli |   | antonio a. casilli |\n",
      "antonio.casilli@googlemail.com antonio.casilli@ehess.fr\n",
      "POSSIBLE DUPLICATE | sandrine clérisse |   | sandrine clérisse |\n",
      "sandrine.clerisse@cnrs.fr sclerisse@parisnanterre.fr\n",
      "POSSIBLE DUPLICATE | frédéric clavert |   | frédéric clavert |\n",
      "frederic.clavert@unil.ch frederic@clavert.net\n",
      "POSSIBLE DUPLICATE | frédéric clavert |   | frédéric clavert |\n",
      "frederic.clavert@unil.ch frederic.clavert@uni.lu\n",
      "POSSIBLE DUPLICATE | gérald kembellec |   | gérald kembellec |\n",
      "gerald.kembellec@cnam.fr gerald.kembellec@lecnam.net\n",
      "POSSIBLE DUPLICATE | jouni tuominen |   | jouni tuominen |\n",
      "jouni.tuominen@helsinki.fi jouni.tuominen@aalto.fi\n",
      "POSSIBLE DUPLICATE | aurélie olivesi |   | aurelie olivesi |\n",
      "aurelie.olivesi@gmail.com aurelie.olivesi@wanadoo.fr\n",
      "176 13\n",
      "[['dominique stutzmann', 'dominique.stutzmann@irht.cnrs.fr'], ['jorge fins', 'jorge.fins@univ-tours.fr'], ['antoine courtin', 'antoine.courtin@mac.com'], ['pierre mounier', 'pierre.mounier@ehess.fr'], ['thierry poibeau', 'thierry.poibeau@ens.fr'], ['laetitia bontemps', 'laetitia.bontemps@univ-tours.fr'], ['st\\xc3\\xa9phane pouyllau', 'stephane.pouyllau@huma-num.fr'], ['georges-xavier blary', 'georges-xavier.blary@unilim.fr'], ['wandl-vogt, eveline', 'eveline.wandl-vogt@oeaw.ac.at'], ['antonio a. casilli', 'antonio.casilli@ehess.fr'], ['claire clivaz', 'claire.clivaz@unil.ch'], ['antoine blanchard', 'antoine.blanchard@gmail.com'], ['elena spadini', 'spadinielena@gmail.com'], ['pablo ruiz', 'pabloruizfabo@gmail.com'], ['laurent romary', 'laurent.romary@inria.fr'], ['olivier le deuff', 'oledeuff@gmail.com'], ['chadier christine', 'christine.chadier@univ-lyon3.fr'], ['aude.da-cruz-lima', 'aude.da-cruz-lima@mae.u-paris10.fr'], ['jerome valluy', 'jerome.valluy@univ-paris1.fr'], ['annael le poullennec', 'annael.le-poullennec@psl.eu'], ['elena gonz\\xc3\\xa1lez-blanco', 'elenagonzalezblanco@yahoo.es'], ['seth van hooland', 'svhoolan@ulb.ac.be'], ['jean-baptiste camps', 'jbcamps@hotmail.com'], ['brunet mich\\xc3\\xa8le', 'iglouvremb@gmail.com'], ['adeline joffres', 'adeline.joffres@huma-num.fr'], ['j\\xc3\\xa9r\\xc3\\xb4me darmont', 'jerome.darmont@univ-lyon2.fr'], ['olivier secardin', 'secardinolivier@yahoo.fr'], ['sylvain laurens', 'laurens@ehess.fr'], ['rails &amp; histoire', 'listes@ahicf.com'], ['enrico natale', 'enrico.natale@infoclio.ch'], ['lisette calderan', 'lisette.calderan@inria.fr'], ['francoise blum', 'francoise.blum@univ-paris1.fr'], ['noiret, serge', 'serge.noiret@eui.eu'], ['manuel zacklad', 'manuel.zacklad@cnam.fr'], ['ekergosien', 'eric.kergosien@univ-lille3.fr'], ['stefanev', 'stefanev@club-internet.fr'], ['laurence rageot', 'laurence.rageot@univ-tours.fr'], ['delegue.general@adbu.fr', 'delegue.general@adbu.fr'], ['b\\xc3\\xa9atrice markhoff', 'beatrice.markhoff@univ-tours.fr'], ['marin dacos', 'marin.dacos@revues.org'], ['clarisse bardiot', 'clarisse_bardiot@mac.com'], ['eric guichard', 'eric.guichard@enssib.fr'], ['elena pierazzo', 'pierazzo@gmail.com'], ['st\\xc3\\xa9phane vial', 'vial.stephane@gmail.com'], ['pierre mounier', 'pierre.mounier@openedition.org'], ['marta severo', 'martaseve@gmail.com'], ['elodie faath', 'elodie.faath@openedition.org'], ['martin grandjean', 'martin.grandjean@unil.ch'], ['sandrine cl\\xc3\\xa9risse', 'sclerisse@parisnanterre.fr'], ['serge heiden', 'slh@ens-lyon.fr'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic@clavert.net'], ['casanova nathalie', 'ncasanova@mmsh.univ-aix.fr'], ['clarisse bardiot', 'clarisse_bardiot@me.com'], ['mareike koenig', 'mkoenig@dhi-paris.fr'], ['epron beno\\xc3\\xaet', 'benoit.epron@enssib.fr'], ['marie-eglantine lescasse', 'marie.e.lescasse@gmail.com'], ['claire clivaz', 'claire.clivaz@sib.swiss'], ['dumouchel suzanne', 'dumouchelsuzanne@yahoo.fr'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@uni.lu'], ['muriel foulonneau', 'muriel.foulonneau@gmail.com'], ['am\\xc3\\xa9lie vairelles', 'amelie.vairelles@sciencespo.fr'], ['alexandre monnin', 'aamonnz@gmail.com'], ['enrica salvatori', 'e.salvatori@mediev.unipi.it'], ['cavallo delphine', 'delphine.cavallo@univ-amu.fr'], ['marjorie burghart', 'marjorie.burghart@ehess.fr'], ['florence andreacola', 'florence.andreacola@univ-grenoble-alpes.fr'], ['michael bourgatte', 'm.bourgatte@icp.fr'], ['johann holland', 'johann.holland@campus-condorcet.fr'], ['st\\xc3\\xa9phane pouyllau', 'stephane.pouyllau@cnrs.fr'], ['nicolas larrousse', 'nicolas.larrousse@huma-num.fr'], ['michel bernard', 'michel.bernard@univ-paris3.fr'], ['sofia papastamkou', 'stamkou@free.fr'], ['paquien-s\\xc3\\xa9guy fran\\xc3\\xa7oise\\t', 'francoise.paquienseguy@sciencespo-lyon.fr'], ['myriam tazi', 'myriam.tazi@sciencespo.fr'], ['julia bonaccorsi', 'julia.bonaccorsi@univ-lyon2.fr'], ['cecile rodrigues', 'cecile.rodrigues@cnrs.fr'], ['marin dacos', 'marin.dacos@openedition.org'], ['aur\\xc3\\xa9lien berra', 'aurelien.berra@gmail.com'], ['laube sylvain', 'sylvain.laube@univ-brest.fr'], ['c\\xc3\\xa9cile boulaire', 'cecile.boulaire@univ-tours.fr'], ['sarah cadorel', 'sarah.cadorel@sciencespo.fr'], ['soudan cecile', 'cecile.soudan@ehess.fr'], ['jeanne herzog', 'jea.herzog@gmail.com'], ['vanessa juloux', 'vanessa.juloux@ephe.sorbonne.fr'], ['aurelie olivesi', 'aurelie.olivesi@wanadoo.fr'], ['formation continue enc', 'formation.continue@enc-sorbonne.fr'], ['beauguitte laurent', 'beauguittelaurent@hotmail.com'], ['irihs', 'irihs@univ-rouen.fr'], ['marie-laure massot', 'marie-laure.massot@ens.fr'], ['epler, jakob', 'jakob.epler@dariah.eu'], ['ren\\xc3\\xa9 audet', 'rene.audet@lit.ulaval.ca'], ['alexandre hocquet', 'alexandre.hocquet@univ-lorraine.fr'], ['g\\xc3\\xa9rald kembellec', 'gerald.kembellec@lecnam.net'], ['fran\\xc3\\xa7ois bavaud', 'francois.bavaud@unil.ch'], ['guillaume blum', 'guillaume.blum@design.ulaval.ca'], ['elina leblanc', 'elinaleblanc3007@gmail.com'], ['inatheque@ina.fr', 'inatheque@ina.fr'], ['annaig mahe', 'mahe.annaig@wanadoo.fr'], ['florence.clavaud@free.fr', 'florence.clavaud@free.fr'], ['anne baillot', 'anne.baillot@gmail.com'], ['jouni tuominen', 'jouni.tuominen@aalto.fi'], ['burghart marjorie', 'marjorie.burghart@ehess.fr'], ['antonio casilli', 'antonio.casilli@googlemail.com'], ['mathieu andro', 'mathieu.andro@versailles.inra.fr'], ['claire lemercier', 'claire.lemercier@sciencespo.fr'], ['marc jahjah', 'jahjah.marc@gmail.com'], ['cristofoli pascal', 'pascal.cristofoli@ehess.fr'], ['equipe projet iglouvre', 'projet.iglouvre@gmail.com'], ['fatiha idmhand', 'fatihaidmhand@yahoo.es'], ['nicolas th\\xc3\\xa9ly', 'nicolasthelyrennes2@gmail.com'], ['marta materni', 'marta.materni@gmail.com'], ['isabelle.thiebau@univ-lille2.fr', 'isabelle.thiebau@univ-lille2.fr'], ['christine michel', 'christine.michel@insa-lyon.fr'], ['r\\xc3\\xa9mi jimenes', 'remi.jimenes@gmail.com'], ['joel marchand', 'joel.marchand@huma-num.fr'], ['arno.zucker@gmail.com', 'arno.zucker@gmail.com'], ['st\\xc3\\xa9phane loret', 'stephane.loret@univ-nantes.fr'], ['michael sinatra', 'michaelesinatra@gmail.com'], ['emmanuelle duwez', 'emmanuelle.duwez@sciencespo.fr'], ['amel fraisse', 'amel.fraisse@univ-lille3.fr'], ['emilien ruiz', 'emilien.ruiz@ehess.fr'], ['gilles pansu', 'gpansu@gmail.com'], ['fran\\xc3\\xa7ois th\\xc3\\xa9ron', 'francois.theron@uvsq.fr'], ['caroline cance', 'caroline.cance@univ-orleans.fr'], ['rapha\\xc3\\xablle bour', 'raphaelle.bour@irit.fr'], ['caroline rossi', 'caroline.rossi@univ-grenoble-alpes.fr'], ['audrey baneyx - sciences po', 'audrey.baneyx@sciencespo.fr'], ['sandrine cl\\xc3\\xa9risse', 'sandrine.clerisse@cnrs.fr'], ['pierre-edouard barrault', 'pe.barrault@gmail.com'], ['francesco beretta', 'francesco.beretta@ish-lyon.cnrs.fr'], ['lamasse', 'stephane.lamasse@univ-paris1.fr'], ['anne-laure brisac-chra\\xc3\\xafbi', 'anne-laure.brisac@inha.fr'], ['nicolas legrand', 'nicolas.legrand@obspm.fr'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@unil.ch'], ['daniel stoekl', 'daniel.stoekl@ephe.sorbonne.fr'], ['mehdi khamassi', 'mehdi.khamassi@upmc.fr'], ['florent laroche', 'florent.laroche@ec-nantes.fr'], ['maud ingarao', 'maud.ingarao@ens-lyon.fr'], ['g\\xc3\\xa9rald kembellec', 'gerald.kembellec@cnam.fr'], ['elisabeth.belmas', 'elisabeth.belmas@wanadoo.fr'], ['anne gresillon', 'gresillon@cmb.hu-berlin.de'], ['caroline muller', 'caroline.muller@univ-reims.fr'], ['cl\\xc3\\xa9mence jacquot', 'clemence.jacquot@gmail.com'], ['emmanuelle morlock', 'emmanuelle.morlock@gmail.com'], ['yosra ghliss', 'yosra.ghliss17@gmail.com'], ['val\\xc3\\xa9rie beaugiraud', 'valerie.beaugiraud@ens-lyon.fr'], ['camille monnier', 'camillemonnier33@hotmail.com'], ['dbernhard@unistra.fr', 'dbernhard@unistra.fr'], ['nancy ottaviano', 'ottaviano.nancy@gmail.com'], ['jouni tuominen', 'jouni.tuominen@helsinki.fi'], ['listes@ahicf.com', 'listes@ahicf.com'], ['cynthia pedroja', 'cynthia.pedroja@meshs.fr'], ['olfa lamloum', 'olfa.lamloum@gmail.com'], ['paul girard', 'paul.girard@sciencespo.fr'], ['marie-noelle.polino@ahicf.com', 'marie-noelle.polino@ahicf.com'], ['cadiou colette', 'colette.cadiou@irstea.fr'], ['yamina bensaadoune', 'yamina.bensaadoune@univ-rouen.fr'], ['sandrine breuil', 'sandrine.breuil@univ-tours.fr'], ['carmen brando', 'carmen.brando@gmail.com'], ['ghislain sillaume', 'ghislain.sillaume@cvce.eu'], ['aur\\xc3\\xa9lie olivesi', 'aurelie.olivesi@gmail.com'], ['alexandre moatti', 'alexandre.moatti@mines.org'], ['emmanuel guez', 'emmanuelguez@yahoo.fr'], ['graham ranger', 'graham.ranger@univ-avignon.fr'], ['jf.omhover@histographe.com', 'jf.omhover@histographe.com'], ['richard walter', 'richard.walter@ens.fr'], ['javier espejo sur\\xc3\\xb3s', 'espejosuros.javier@gmail.com'], ['viera rebolledo-dhuin', 'viera.rebolledodhuin@free.fr'], ['hannoun judith', 'judith.hannoun@univ-amu.fr'], ['recherche.coordination@bnf.fr', 'recherche.coordination@bnf.fr'], ['isabelle thiebau', 'isabelle.thiebau@univ-lille2.fr'], ['raphaelle brangier', 'raphaelle.krummeich@univ-rouen.fr'], ['nadine dardenne', 'nadine.dardenne@cnrs.fr'], ['th\\xc3\\xa9ly nicolas', 'nicolas.thely@univ-rennes2.fr'], ['h\\xc3\\xa9l\\xc3\\xa8ne de foucaud', 'hdefouca@u-paris10.fr'], ['marionlame@gmail.com', 'marionlame@gmail.com']]\n",
      "________________________\n",
      "\n",
      "[[['pierre mounier', 'pierre.mounier@openedition.org'], ['pierre mounier', 'pierre.mounier@ehess.fr']], [['clarisse bardiot', 'clarisse_bardiot@me.com'], ['clarisse bardiot', 'clarisse_bardiot@mac.com']], [['claire clivaz', 'claire.clivaz@sib.swiss'], ['claire clivaz', 'claire.clivaz@unil.ch']], [['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@uni.lu'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic@clavert.net']], [['st\\xc3\\xa9phane pouyllau', 'stephane.pouyllau@cnrs.fr'], ['st\\xc3\\xa9phane pouyllau', 'stephane.pouyllau@huma-num.fr']], [['marin dacos', 'marin.dacos@openedition.org'], ['marin dacos', 'marin.dacos@revues.org']], [['antonio casilli', 'antonio.casilli@googlemail.com'], ['antonio a. casilli', 'antonio.casilli@ehess.fr']], [['sandrine cl\\xc3\\xa9risse', 'sandrine.clerisse@cnrs.fr'], ['sandrine cl\\xc3\\xa9risse', 'sclerisse@parisnanterre.fr']], [['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@unil.ch'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic@clavert.net']], [['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@unil.ch'], ['fr\\xc3\\xa9d\\xc3\\xa9ric clavert', 'frederic.clavert@uni.lu']], [['g\\xc3\\xa9rald kembellec', 'gerald.kembellec@cnam.fr'], ['g\\xc3\\xa9rald kembellec', 'gerald.kembellec@lecnam.net']], [['jouni tuominen', 'jouni.tuominen@helsinki.fi'], ['jouni tuominen', 'jouni.tuominen@aalto.fi']], [['aur\\xc3\\xa9lie olivesi', 'aurelie.olivesi@gmail.com'], ['aurelie olivesi', 'aurelie.olivesi@wanadoo.fr']]]\n"
     ]
    }
   ],
   "source": [
    "liste_noms_and_dups=read_corpus_and_extract_names(corpus_mails_DH)\n",
    "print len(liste_noms_and_dups[0]),len(liste_noms_and_dups[1])\n",
    "print liste_noms_and_dups[0]\n",
    "print \"________________________\\n\"\n",
    "print liste_noms_and_dups[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annael le poullennec': [['annael.le-poullennec@psl.eu', datetime.datetime(2018, 3, 1, 14, 3, 55, tzinfo=tzutc()), datetime.datetime(2018, 3, 1, 14, 3, 55, tzinfo=tzutc())]], 'marie-eglantine lescasse': [['marie.e.lescasse@gmail.com', datetime.datetime(2018, 3, 28, 17, 9, 57, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 28, 17, 9, 57, tzinfo=tzoffset(None, 7200))]], 'brunet mich\\xc3\\xa8le': [['iglouvremb@gmail.com', datetime.datetime(2014, 7, 17, 14, 17, 4, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 17, 14, 17, 4, tzinfo=tzoffset(None, 7200))]], 'irihs': [['irihs@univ-rouen.fr', datetime.datetime(2018, 3, 15, 9, 12, 21, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 15, 9, 12, 21, tzinfo=tzoffset(None, 3600))]], 'antonio casilli': [['antonio.casilli@googlemail.com', datetime.datetime(2014, 7, 7, 11, 23, 8, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 7, 11, 23, 8, tzinfo=tzoffset(None, 7200))], ['antonio.casilli@ehess.fr', datetime.datetime(2018, 3, 12, 8, 56, 36, tzinfo=tzlocal()), datetime.datetime(2018, 3, 13, 7, 55, 52, tzinfo=tzlocal())]], 'mehdi khamassi': [['mehdi.khamassi@upmc.fr', datetime.datetime(2016, 7, 3, 7, 31, 28, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 3, 7, 31, 28, tzinfo=tzoffset(None, 7200))]], 'laube sylvain': [['sylvain.laube@univ-brest.fr', datetime.datetime(2014, 7, 25, 22, 53, 36, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 21, 16, 16, 6, tzinfo=tzoffset(None, 3600))]], 'carmen brando': [['carmen.brando@gmail.com', datetime.datetime(2017, 6, 7, 14, 12, 9, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 7, 14, 12, 9, tzinfo=tzoffset(None, 7200))]], 'delegue.general@adbu.fr': [['delegue.general@adbu.fr', datetime.datetime(2017, 6, 13, 15, 36, 29, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 13, 15, 36, 29, tzinfo=tzoffset(None, 7200))]], 'adeline joffres': [['adeline.joffres@huma-num.fr', datetime.datetime(2018, 3, 26, 11, 36, 23, tzinfo=tzlocal()), datetime.datetime(2018, 3, 26, 12, 4, 54, tzinfo=tzlocal())]], 'yosra ghliss': [['yosra.ghliss17@gmail.com', datetime.datetime(2017, 6, 6, 17, 17, 31, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 6, 17, 17, 31, tzinfo=tzoffset(None, 7200))]], 'anne gresillon': [['gresillon@cmb.hu-berlin.de', datetime.datetime(2018, 3, 7, 15, 44, 1, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 7, 15, 44, 1, tzinfo=tzoffset(None, 3600))]], 'olfa lamloum': [['olfa.lamloum@gmail.com', datetime.datetime(2018, 3, 26, 14, 32, 33, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 26, 14, 32, 33, tzinfo=tzoffset(None, 3600))]], 'marta severo': [['martaseve@gmail.com', datetime.datetime(2015, 7, 24, 15, 52, 17, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 24, 15, 52, 17, tzinfo=tzoffset(None, 7200))]], 'claire lemercier': [['claire.lemercier@sciencespo.fr', datetime.datetime(2018, 3, 14, 10, 3, 2, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 14, 10, 3, 2, tzinfo=tzoffset(None, 3600))]], 'am\\xc3\\xa9lie vairelles': [['amelie.vairelles@sciencespo.fr', datetime.datetime(2018, 3, 23, 17, 23, 21, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 23, 17, 23, 21, tzinfo=tzoffset(None, 3600))]], 'wandl-vogt, eveline': [['eveline.wandl-vogt@oeaw.ac.at', datetime.datetime(2017, 6, 25, 22, 53, 30, tzinfo=tzutc()), datetime.datetime(2017, 6, 26, 20, 54, 38, tzinfo=tzutc())]], 'sylvain laurens': [['laurens@ehess.fr', datetime.datetime(2015, 7, 9, 11, 45, 25, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 9, 11, 45, 25, tzinfo=tzoffset(None, 7200))]], 'florence.clavaud@free.fr': [['florence.clavaud@free.fr', datetime.datetime(2018, 3, 2, 15, 36, 5, tzinfo=tzlocal()), datetime.datetime(2018, 3, 2, 15, 36, 5, tzinfo=tzlocal())]], 'burghart marjorie': [['marjorie.burghart@ehess.fr', datetime.datetime(2013, 7, 5, 1, 35, 31, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 9, 13, 52, 33, tzinfo=tzlocal())]], 'michael bourgatte': [['m.bourgatte@icp.fr', datetime.datetime(2016, 7, 19, 14, 37, 11, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 19, 14, 37, 11, tzinfo=tzoffset(None, 7200))]], 'vanessa juloux': [['vanessa.juloux@ephe.sorbonne.fr', datetime.datetime(2017, 6, 1, 18, 59, 10, tzinfo=tzutc()), datetime.datetime(2017, 6, 1, 18, 59, 10, tzinfo=tzutc())]], 'beauguitte laurent': [['beauguittelaurent@hotmail.com', datetime.datetime(2017, 6, 28, 8, 20, 32, tzinfo=tzutc()), datetime.datetime(2017, 6, 28, 8, 20, 32, tzinfo=tzutc())]], 'st\\xc3\\xa9phane loret': [['stephane.loret@univ-nantes.fr', datetime.datetime(2015, 7, 10, 10, 55, 45, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 8, 15, 40, 3, tzinfo=tzoffset(None, 7200))]], 'yamina bensaadoune': [['yamina.bensaadoune@univ-rouen.fr', datetime.datetime(2015, 7, 15, 17, 7, 53, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 15, 17, 7, 53, tzinfo=tzoffset(None, 7200))]], 'soudan cecile': [['cecile.soudan@ehess.fr', datetime.datetime(2014, 7, 6, 15, 51, 49, tzinfo=tzlocal()), datetime.datetime(2014, 7, 6, 15, 51, 49, tzinfo=tzlocal())]], 'paquien-s\\xc3\\xa9guy fran\\xc3\\xa7oise\\t': [['francoise.paquienseguy@sciencespo-lyon.fr', datetime.datetime(2017, 6, 9, 8, 5, 48, tzinfo=tzutc()), datetime.datetime(2017, 6, 16, 18, 12, 58, tzinfo=tzutc())]], 'joel marchand': [['joel.marchand@huma-num.fr', datetime.datetime(2018, 3, 26, 9, 0, 20, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 26, 9, 0, 20, tzinfo=tzoffset(None, 7200))]], 'pierre-edouard barrault': [['pe.barrault@gmail.com', datetime.datetime(2015, 7, 10, 19, 43, 36, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 10, 19, 43, 36, tzinfo=tzoffset(None, 7200))]], 'r\\xc3\\xa9mi jimenes': [['remi.jimenes@gmail.com', datetime.datetime(2017, 6, 21, 12, 12, 42, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 21, 12, 12, 42, tzinfo=tzoffset(None, 7200))]], 'claire clivaz': [['claire.clivaz@sib.swiss', datetime.datetime(2016, 7, 20, 16, 54, 26, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 29, 13, 21, 16, tzinfo=tzoffset(None, 7200))], ['claire.clivaz@unil.ch', datetime.datetime(2013, 7, 9, 15, 28, 26, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 12, 12, 31, 28, tzinfo=tzoffset(None, 7200))]], 'cavallo delphine': [['delphine.cavallo@univ-amu.fr', datetime.datetime(2018, 3, 13, 10, 19, 25, tzinfo=tzutc()), datetime.datetime(2018, 3, 29, 10, 23, 54, tzinfo=tzutc())]], 'olivier le deuff': [['oledeuff@gmail.com', datetime.datetime(2013, 7, 12, 15, 54, 35, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 6, 11, 48, 1, tzinfo=tzoffset(None, 3600))]], 'equipe projet iglouvre': [['projet.iglouvre@gmail.com', datetime.datetime(2014, 7, 17, 12, 39, 42, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 17, 12, 39, 42, tzinfo=tzoffset(None, 7200))]], 'pablo ruiz': [['pabloruizfabo@gmail.com', datetime.datetime(2017, 6, 14, 10, 17, 22, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 14, 10, 17, 22, tzinfo=tzoffset(None, 7200))]], 'audrey baneyx - sciences po': [['audrey.baneyx@sciencespo.fr', datetime.datetime(2015, 7, 27, 14, 16, 20, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 27, 14, 16, 20, tzinfo=tzoffset(None, 7200))]], 'manuel zacklad': [['manuel.zacklad@cnam.fr', datetime.datetime(2015, 7, 12, 18, 26, 27, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 12, 18, 26, 27, tzinfo=tzoffset(None, 7200))]], 'francoise blum': [['francoise.blum@univ-paris1.fr', datetime.datetime(2017, 6, 26, 17, 4, 56, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 26, 17, 4, 56, tzinfo=tzoffset(None, 7200))]], 'marie-laure massot': [['marie-laure.massot@ens.fr', datetime.datetime(2017, 6, 26, 16, 30, 12, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 15, 14, 40, 57, tzinfo=tzoffset(None, 3600))]], 'elena pierazzo': [['pierazzo@gmail.com', datetime.datetime(2018, 3, 20, 12, 33, 7, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 20, 12, 33, 7, tzinfo=tzoffset(None, 3600))]], 'amel fraisse': [['amel.fraisse@univ-lille3.fr', datetime.datetime(2018, 3, 6, 14, 57, 59, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 6, 14, 57, 59, tzinfo=tzoffset(None, 3600))]], 'mathieu andro': [['mathieu.andro@versailles.inra.fr', datetime.datetime(2015, 7, 9, 12, 5, 28, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 9, 12, 5, 28, tzinfo=tzoffset(None, 7200))]], 'eric guichard': [['eric.guichard@enssib.fr', datetime.datetime(2013, 7, 10, 15, 56, 42, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 19, 19, 7, 45, tzinfo=tzoffset(None, 7200))]], 'anne-laure brisac-chra\\xc3\\xafbi': [['anne-laure.brisac@inha.fr', ' Fri, 13 Jul 2012 09:56:18 +0100', ' Fri, 13 Jul 2012 09:56:18 +0100']], 'serge heiden': [['slh@ens-lyon.fr', datetime.datetime(2012, 7, 26, 21, 21, 27, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 15, 11, 33, 42, tzinfo=tzoffset(None, 3600))]], 'laurent romary': [['laurent.romary@inria.fr', datetime.datetime(2014, 7, 30, 15, 35, 56, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 6, 19, 1, 56, tzinfo=tzoffset(None, 7200))]], 'guillaume blum': [['guillaume.blum@design.ulaval.ca', datetime.datetime(2017, 6, 21, 17, 16, 28, tzinfo=tzutc()), datetime.datetime(2017, 6, 21, 17, 16, 28, tzinfo=tzutc())]], 'rapha\\xc3\\xablle bour': [['raphaelle.bour@irit.fr', datetime.datetime(2018, 3, 21, 12, 43, 49, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 21, 12, 43, 49, tzinfo=tzoffset(None, 3600))]], 'antoine blanchard': [['antoine.blanchard@gmail.com', datetime.datetime(2013, 7, 18, 10, 47, 22, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 18, 10, 47, 22, tzinfo=tzoffset(None, 7200))]], 'florent laroche': [['florent.laroche@ec-nantes.fr', datetime.datetime(2017, 6, 26, 19, 5, 41, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 26, 19, 5, 41, tzinfo=tzoffset(None, 7200))]], 'cadiou colette': [['colette.cadiou@irstea.fr', datetime.datetime(2016, 7, 20, 11, 48, 26, tzinfo=tzlocal()), datetime.datetime(2016, 7, 20, 11, 48, 26, tzinfo=tzlocal())]], 'viera rebolledo-dhuin': [['viera.rebolledodhuin@free.fr', datetime.datetime(2014, 7, 16, 20, 28, 39, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 16, 20, 28, 39, tzinfo=tzoffset(None, 7200))]], 'thierry poibeau': [['thierry.poibeau@ens.fr', datetime.datetime(2018, 3, 5, 7, 56, 29, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 26, 9, 17, tzinfo=tzoffset(None, 7200))]], 'fatiha idmhand': [['fatihaidmhand@yahoo.es', datetime.datetime(2016, 7, 19, 9, 59, 52, tzinfo=tzutc()), datetime.datetime(2016, 7, 19, 9, 59, 52, tzinfo=tzutc())]], 'dominique stutzmann': [['dominique.stutzmann@irht.cnrs.fr', datetime.datetime(2012, 7, 2, 8, 25, 19, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 27, 14, 18, 48, tzinfo=tzoffset(None, 7200))]], 'sandrine cl\\xc3\\xa9risse': [['sandrine.clerisse@cnrs.fr', datetime.datetime(2018, 3, 21, 10, 40, 36, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 21, 10, 40, 36, tzinfo=tzoffset(None, 3600))], ['sclerisse@parisnanterre.fr', datetime.datetime(2018, 3, 21, 10, 33, 6, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 21, 10, 33, 6, tzinfo=tzoffset(None, 3600))]], 'caroline cance': [['caroline.cance@univ-orleans.fr', datetime.datetime(2018, 3, 21, 9, 24, 41, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 21, 9, 24, 41, tzinfo=tzoffset(None, 3600))]], 'sandrine breuil': [['sandrine.breuil@univ-tours.fr', datetime.datetime(2013, 7, 9, 8, 45, 6, tzinfo=tzoffset(u'BST', 3600)), datetime.datetime(2013, 7, 9, 8, 45, 6, tzinfo=tzoffset(u'BST', 3600))]], 'cristofoli pascal': [['pascal.cristofoli@ehess.fr', datetime.datetime(2018, 3, 12, 12, 39, 6, tzinfo=tzlocal()), datetime.datetime(2018, 3, 12, 12, 39, 6, tzinfo=tzlocal())]], 'muriel foulonneau': [['muriel.foulonneau@gmail.com', datetime.datetime(2010, 7, 16, 10, 57, 19, tzinfo=tzoffset(None, 7200)), datetime.datetime(2010, 7, 16, 10, 57, 19, tzinfo=tzoffset(None, 7200))]], 'laetitia bontemps': [['laetitia.bontemps@univ-tours.fr', datetime.datetime(2011, 7, 19, 15, 4, 42, tzinfo=tzoffset(u'BST', 3600)), datetime.datetime(2011, 7, 19, 15, 4, 42, tzinfo=tzoffset(u'BST', 3600))]], 'emilien ruiz': [['emilien.ruiz@ehess.fr', datetime.datetime(2012, 7, 2, 14, 47, 31, tzinfo=tzoffset(None, 7200)), datetime.datetime(2012, 7, 2, 14, 47, 31, tzinfo=tzoffset(None, 7200))]], 'emmanuel guez': [['emmanuelguez@yahoo.fr', datetime.datetime(2014, 7, 22, 17, 24, 51, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 22, 17, 24, 51, tzinfo=tzoffset(None, 7200))]], 'enrica salvatori': [['e.salvatori@mediev.unipi.it', datetime.datetime(2014, 7, 11, 10, 0, 21, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 11, 10, 0, 21, tzinfo=tzoffset(None, 7200))]], 'mareike koenig': [['mkoenig@dhi-paris.fr', datetime.datetime(2013, 7, 5, 14, 36, 19, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 14, 14, 57, 17, tzinfo=tzoffset(None, 7200))]], 'javier espejo sur\\xc3\\xb3s': [['espejosuros.javier@gmail.com', datetime.datetime(2013, 7, 12, 22, 12, 37, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 12, 22, 12, 37, tzinfo=tzoffset(None, 7200))]], 'jean-baptiste camps': [['jbcamps@hotmail.com', datetime.datetime(2017, 6, 2, 12, 43, 25, tzinfo=tzutc()), datetime.datetime(2017, 6, 2, 12, 43, 25, tzinfo=tzutc())]], 'fran\\xc3\\xa7ois bavaud': [['francois.bavaud@unil.ch', datetime.datetime(2018, 3, 16, 8, 5, 59, tzinfo=tzutc()), datetime.datetime(2018, 3, 16, 8, 5, 59, tzinfo=tzutc())]], 'isabelle.thiebau@univ-lille2.fr': [['isabelle.thiebau@univ-lille2.fr', datetime.datetime(2016, 7, 6, 18, 52, 24, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 20, 0, 0, 32, tzinfo=tzoffset(None, 7200))]], 'ren\\xc3\\xa9 audet': [['rene.audet@lit.ulaval.ca', datetime.datetime(2018, 3, 21, 14, 11, 14, tzinfo=tzutc()), datetime.datetime(2018, 3, 21, 14, 11, 14, tzinfo=tzutc())]], 'anne baillot': [['anne.baillot@gmail.com', datetime.datetime(2015, 7, 26, 16, 15, 52, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 20, 13, 59, 42, tzinfo=tzoffset(None, 3600))]], 'seth van hooland': [['svhoolan@ulb.ac.be', datetime.datetime(2018, 3, 2, 11, 1, 59, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 29, 15, 57, 2, tzinfo=tzoffset(None, 7200))]], 'g\\xc3\\xa9rald kembellec': [['gerald.kembellec@cnam.fr', datetime.datetime(2015, 7, 13, 12, 46, 15, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 26, 19, 12, 16, tzinfo=tzoffset(None, 7200))], ['gerald.kembellec@lecnam.net', datetime.datetime(2016, 7, 6, 18, 55, 47, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 6, 18, 55, 47, tzinfo=tzoffset(None, 7200))]], 'maud ingarao': [['maud.ingarao@ens-lyon.fr', datetime.datetime(2011, 7, 7, 15, 59, 17, tzinfo=tzoffset(None, 7200)), datetime.datetime(2011, 7, 7, 15, 59, 17, tzinfo=tzoffset(None, 7200))]], 'michael sinatra': [['michaelesinatra@gmail.com', datetime.datetime(2014, 7, 9, 4, 1, 53, tzinfo=tzoffset(None, -14400)), datetime.datetime(2014, 7, 9, 4, 1, 53, tzinfo=tzoffset(None, -14400))]], 'listes@ahicf.com': [['listes@ahicf.com', datetime.datetime(2013, 7, 18, 10, 20, 44, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 28, 16, 43, 54, tzinfo=tzoffset(None, 7200))]], 'recherche.coordination@bnf.fr': [['recherche.coordination@bnf.fr', datetime.datetime(2018, 3, 12, 8, 39, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 8, 39, tzinfo=tzoffset(None, 3600))]], 'nicolas larrousse': [['nicolas.larrousse@huma-num.fr', datetime.datetime(2017, 6, 6, 17, 11, 37, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 9, 15, 47, 7, tzinfo=tzoffset(None, 7200))]], 'emmanuelle morlock': [['emmanuelle.morlock@gmail.com', datetime.datetime(2015, 7, 11, 19, 24, 29, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 11, 19, 24, 29, tzinfo=tzoffset(None, 7200))]], 'formation continue enc': [['formation.continue@enc-sorbonne.fr', datetime.datetime(2016, 7, 5, 15, 46, 59, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 5, 15, 46, 59, tzinfo=tzoffset(None, 7200))]], 'richard walter': [['richard.walter@ens.fr', datetime.datetime(2016, 7, 12, 16, 3, 9, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 12, 16, 3, 9, tzinfo=tzoffset(None, 7200))]], 'noiret, serge': [['serge.noiret@eui.eu', datetime.datetime(2011, 7, 18, 2, 6, 6, tzinfo=tzoffset(None, -25200)), datetime.datetime(2015, 7, 3, 10, 17, 19, tzinfo=tzutc())]], 'fr\\xc3\\xa9d\\xc3\\xa9ric clavert': [['frederic.clavert@uni.lu', datetime.datetime(2018, 3, 12, 11, 53, 38, tzinfo=tzutc()), datetime.datetime(2018, 3, 27, 11, 23, 8, tzinfo=tzutc())], ['frederic@clavert.net', datetime.datetime(2012, 7, 10, 10, 39, 11, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 2, 15, 41, 35, tzinfo=tzoffset(None, 7200))], [['frederic.clavert@unil.ch', datetime.datetime(2016, 7, 7, 13, 11, 56, tzinfo=tzutc()), datetime.datetime(2016, 7, 7, 13, 11, 56, tzinfo=tzutc())], ['frederic@clavert.net', datetime.datetime(2012, 7, 10, 10, 39, 11, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 2, 15, 41, 35, tzinfo=tzoffset(None, 7200))]], [['frederic.clavert@unil.ch', datetime.datetime(2016, 7, 7, 13, 11, 56, tzinfo=tzutc()), datetime.datetime(2016, 7, 7, 13, 11, 56, tzinfo=tzutc())], ['frederic.clavert@uni.lu', datetime.datetime(2018, 3, 12, 11, 53, 38, tzinfo=tzutc()), datetime.datetime(2018, 3, 27, 11, 23, 8, tzinfo=tzutc())]]], 'chadier christine': [['christine.chadier@univ-lyon3.fr', datetime.datetime(2015, 7, 30, 9, 52, 1, tzinfo=tzutc()), datetime.datetime(2015, 7, 30, 9, 59, 31, tzinfo=tzutc())]], 'elena gonz\\xc3\\xa1lez-blanco': [['elenagonzalezblanco@yahoo.es', datetime.datetime(2015, 7, 7, 23, 20, 18, tzinfo=tzutc()), datetime.datetime(2016, 7, 18, 0, 53, 35, tzinfo=tzutc())]], 'pierre mounier': [['pierre.mounier@openedition.org', datetime.datetime(2013, 7, 5, 10, 9, 24, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 5, 11, 11, tzinfo=tzoffset(None, 3600))], ['pierre.mounier@ehess.fr', datetime.datetime(2013, 7, 5, 12, 13, 22, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 5, 12, 13, 22, tzinfo=tzoffset(None, 7200))]], 'jorge fins': [['jorge.fins@univ-tours.fr', datetime.datetime(2017, 6, 8, 13, 51, 2, tzinfo=tzlocal()), datetime.datetime(2017, 6, 19, 10, 6, 25, tzinfo=tzlocal())]], 'annaig mahe': [['mahe.annaig@wanadoo.fr', datetime.datetime(2013, 7, 26, 15, 37, 16, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 26, 15, 37, 16, tzinfo=tzoffset(None, 7200))]], 'myriam tazi': [['myriam.tazi@sciencespo.fr', datetime.datetime(2017, 6, 8, 12, 11, 54, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 12, 8, 42, 16, tzinfo=tzoffset(None, 7200))]], 'caroline muller': [['caroline.muller@univ-reims.fr', datetime.datetime(2016, 7, 11, 20, 40, 8, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 11, 20, 40, 8, tzinfo=tzoffset(None, 7200))]], 'st\\xc3\\xa9phane vial': [['vial.stephane@gmail.com', datetime.datetime(2017, 6, 11, 14, 29, 59, tzinfo=tzutc()), datetime.datetime(2018, 3, 6, 10, 58, 35, tzinfo=tzutc())]], 'jeanne herzog': [['jea.herzog@gmail.com', datetime.datetime(2017, 6, 10, 7, 37, 15, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 10, 7, 37, 15, tzinfo=tzoffset(None, 7200))]], 'olivier secardin': [['secardinolivier@yahoo.fr', datetime.datetime(2017, 6, 18, 21, 48, 44, tzinfo=tzutc()), datetime.datetime(2017, 6, 18, 21, 48, 44, tzinfo=tzutc())]], 'nicolas th\\xc3\\xa9ly': [['nicolasthelyrennes2@gmail.com', datetime.datetime(2017, 6, 12, 14, 18, 46, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 12, 14, 18, 46, tzinfo=tzoffset(None, 7200))]], 'camille monnier': [['camillemonnier33@hotmail.com', datetime.datetime(2017, 6, 12, 9, 19, 59, tzinfo=tzutc()), datetime.datetime(2017, 6, 12, 9, 19, 59, tzinfo=tzutc())]], 'gilles pansu': [['gpansu@gmail.com', datetime.datetime(2017, 6, 9, 16, 32, 46, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 9, 16, 32, 46, tzinfo=tzoffset(None, 7200))]], 'julia bonaccorsi': [['julia.bonaccorsi@univ-lyon2.fr', datetime.datetime(2016, 7, 1, 12, 39, 37, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 1, 12, 39, 37, tzinfo=tzoffset(None, 7200))]], 'nadine dardenne': [['nadine.dardenne@cnrs.fr', datetime.datetime(2017, 6, 19, 17, 21, 6, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 19, 17, 21, 6, tzinfo=tzoffset(None, 7200))]], 'caroline rossi': [['caroline.rossi@univ-grenoble-alpes.fr', datetime.datetime(2017, 6, 16, 15, 27, 11, tzinfo=tzlocal()), datetime.datetime(2017, 6, 16, 15, 27, 11, tzinfo=tzlocal())]], 'michel bernard': [['michel.bernard@univ-paris3.fr', datetime.datetime(2014, 7, 10, 9, 9, 21, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 9, 17, 52, 54, tzinfo=tzoffset(None, 3600))]], 'elena spadini': [['spadinielena@gmail.com', datetime.datetime(2015, 7, 16, 12, 16, 27, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 16, 12, 16, 27, tzinfo=tzoffset(None, 7200))]], 'clarisse bardiot': [['clarisse_bardiot@me.com', datetime.datetime(2015, 7, 9, 14, 46, 14, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 9, 14, 46, 14, tzinfo=tzoffset(None, 7200))], ['clarisse_bardiot@mac.com', datetime.datetime(2017, 6, 7, 13, 19, 2, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 10, 9, 19, 4, tzinfo=tzoffset(None, 7200))]], 'elodie faath': [['elodie.faath@openedition.org', datetime.datetime(2018, 3, 28, 15, 32, 23, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 28, 15, 32, 23, tzinfo=tzoffset(None, 7200))]], 'georges-xavier blary': [['georges-xavier.blary@unilim.fr', datetime.datetime(2018, 3, 12, 11, 0, 23, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 11, 0, 23, tzinfo=tzoffset(None, 3600))]], 'lamasse': [['stephane.lamasse@univ-paris1.fr', datetime.datetime(2018, 3, 9, 19, 46, 27, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 19, 23, 47, tzinfo=tzoffset(None, 3600))]], 'fran\\xc3\\xa7ois th\\xc3\\xa9ron': [['francois.theron@uvsq.fr', datetime.datetime(2017, 6, 2, 12, 36, 14, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 2, 12, 36, 14, tzinfo=tzoffset(None, 7200))]], 'raphaelle brangier': [['raphaelle.krummeich@univ-rouen.fr', datetime.datetime(2018, 3, 19, 18, 2, 18, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 19, 18, 2, 18, tzinfo=tzoffset(None, 3600))]], 'paul girard': [['paul.girard@sciencespo.fr', datetime.datetime(2013, 7, 15, 9, 34, 39, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 15, 9, 34, 39, tzinfo=tzoffset(None, 7200))]], 'jf.omhover@histographe.com': [['jf.omhover@histographe.com', datetime.datetime(2012, 7, 24, 17, 45, 29, tzinfo=tzoffset(None, 7200)), datetime.datetime(2012, 7, 24, 17, 45, 29, tzinfo=tzoffset(None, 7200))]], 'marjorie burghart': [['marjorie.burghart@ehess.fr', datetime.datetime(2013, 7, 5, 1, 35, 31, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 9, 13, 52, 33, tzinfo=tzlocal())]], 'aude.da-cruz-lima': [['aude.da-cruz-lima@mae.u-paris10.fr', datetime.datetime(2016, 7, 28, 9, 38, 17, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 28, 9, 38, 17, tzinfo=tzoffset(None, 7200))]], 'isabelle thiebau': [['isabelle.thiebau@univ-lille2.fr', datetime.datetime(2016, 7, 6, 18, 52, 24, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 20, 0, 0, 32, tzinfo=tzoffset(None, 7200))]], 'alexandre moatti': [['alexandre.moatti@mines.org', datetime.datetime(2013, 7, 24, 19, 28, 45, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 24, 19, 28, 45, tzinfo=tzoffset(None, 7200))]], 'nancy ottaviano': [['ottaviano.nancy@gmail.com', datetime.datetime(2014, 7, 9, 22, 34, 26, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 9, 22, 34, 26, tzinfo=tzoffset(None, 7200))]], 'rails &amp; histoire': [['listes@ahicf.com', datetime.datetime(2013, 7, 18, 10, 20, 44, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 28, 16, 43, 54, tzinfo=tzoffset(None, 7200))]], 'elisabeth.belmas': [['elisabeth.belmas@wanadoo.fr', datetime.datetime(2014, 7, 29, 12, 4, 36, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 29, 12, 4, 36, tzinfo=tzoffset(None, 7200))]], 'alexandre hocquet': [['alexandre.hocquet@univ-lorraine.fr', datetime.datetime(2017, 6, 27, 14, 19, 29, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 27, 14, 19, 29, tzinfo=tzoffset(None, 7200))]], 'daniel stoekl': [['daniel.stoekl@ephe.sorbonne.fr', datetime.datetime(2017, 6, 16, 6, 45, 25, tzinfo=tzutc()), datetime.datetime(2017, 6, 16, 6, 45, 25, tzinfo=tzutc())]], 'c\\xc3\\xa9cile boulaire': [['cecile.boulaire@univ-tours.fr', datetime.datetime(2014, 7, 9, 20, 12, 7, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 9, 20, 12, 7, tzinfo=tzoffset(None, 7200))]], 'jouni tuominen': [['jouni.tuominen@helsinki.fi', datetime.datetime(2017, 6, 1, 20, 0, 43, tzinfo=tzoffset(None, 10800)), datetime.datetime(2017, 6, 1, 20, 0, 43, tzinfo=tzoffset(None, 10800))], ['jouni.tuominen@aalto.fi', datetime.datetime(2018, 3, 13, 14, 20, 26, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 13, 14, 20, 26, tzinfo=tzoffset(None, 7200))]], 'christine michel': [['christine.michel@insa-lyon.fr', datetime.datetime(2016, 7, 28, 19, 24, 3, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 28, 19, 24, 3, tzinfo=tzoffset(None, 7200))]], 'nicolas legrand': [['nicolas.legrand@obspm.fr', datetime.datetime(2013, 7, 5, 14, 59, 58, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 15, 10, 46, 43, tzinfo=tzoffset(None, 7200))]], 'epron beno\\xc3\\xaet': [['benoit.epron@enssib.fr', datetime.datetime(2017, 6, 9, 11, 29, 3, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 9, 11, 29, 3, tzinfo=tzoffset(None, 7200))]], 'alexandre monnin': [['aamonnz@gmail.com', datetime.datetime(2012, 7, 17, 7, 17, 9, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 10, 5, 14, 24, tzinfo=tzoffset(None, 7200))]], 'th\\xc3\\xa9ly nicolas': [['nicolas.thely@univ-rennes2.fr', datetime.datetime(2013, 7, 2, 14, 15, 54, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 2, 14, 15, 54, tzinfo=tzoffset(None, 7200))]], 'graham ranger': [['graham.ranger@univ-avignon.fr', datetime.datetime(2018, 3, 15, 20, 45, 58, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 15, 20, 45, 58, tzinfo=tzoffset(None, 3600))]], 'b\\xc3\\xa9atrice markhoff': [['beatrice.markhoff@univ-tours.fr', datetime.datetime(2017, 6, 13, 14, 27, 18, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 4, 11, 39, 36, tzinfo=tzoffset(None, 3600))]], 'sofia papastamkou': [['stamkou@free.fr', datetime.datetime(2015, 7, 13, 17, 8, 22, tzinfo=tzlocal()), datetime.datetime(2017, 6, 10, 9, 8, 54, tzinfo=tzlocal())]], 'martin grandjean': [['martin.grandjean@unil.ch', datetime.datetime(2016, 7, 6, 16, 1, 43, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 19, 14, 6, 2, tzinfo=tzoffset(None, 3600))]], 'sarah cadorel': [['sarah.cadorel@sciencespo.fr', datetime.datetime(2016, 7, 13, 15, 27, 26, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 13, 15, 27, 26, tzinfo=tzoffset(None, 7200))]], 'lisette calderan': [['lisette.calderan@inria.fr', datetime.datetime(2014, 7, 9, 11, 48, 10, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 9, 11, 48, 10, tzinfo=tzoffset(None, 7200))]], 'dbernhard@unistra.fr': [['dbernhard@unistra.fr', datetime.datetime(2018, 3, 26, 12, 32, 35, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 26, 12, 32, 35, tzinfo=tzoffset(None, 7200))]], 'hannoun judith': [['judith.hannoun@univ-amu.fr', datetime.datetime(2018, 3, 2, 15, 19, 10, tzinfo=tzutc()), datetime.datetime(2018, 3, 2, 15, 19, 10, tzinfo=tzutc())]], 'marc jahjah': [['jahjah.marc@gmail.com', datetime.datetime(2018, 3, 12, 14, 46, 23, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 14, 46, 23, tzinfo=tzoffset(None, 3600))]], 'aur\\xc3\\xa9lie olivesi': [['aurelie.olivesi@gmail.com', datetime.datetime(2015, 7, 16, 0, 22, 43, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 16, 0, 22, 43, tzinfo=tzoffset(None, 7200))], ['aurelie.olivesi@wanadoo.fr', datetime.datetime(2014, 7, 9, 22, 2, 2, tzinfo=tzlocal()), datetime.datetime(2014, 7, 9, 22, 2, 2, tzinfo=tzlocal())]], 'marta materni': [['marta.materni@gmail.com', datetime.datetime(2017, 6, 9, 10, 25, 58, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 9, 10, 25, 58, tzinfo=tzoffset(None, 7200))]], 'marie-noelle.polino@ahicf.com': [['marie-noelle.polino@ahicf.com', datetime.datetime(2015, 7, 2, 14, 10, 25, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 2, 14, 10, 25, tzinfo=tzoffset(None, 7200))]], 'inatheque@ina.fr': [['inatheque@ina.fr', datetime.datetime(2018, 3, 15, 17, 28, 55), datetime.datetime(2018, 3, 15, 17, 28, 55)]], 'enrico natale': [['enrico.natale@infoclio.ch', datetime.datetime(2012, 7, 10, 14, 8, 20, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 8, 15, 8, 24, tzinfo=tzoffset(None, 7200))]], 'marin dacos': [['marin.dacos@openedition.org', datetime.datetime(2012, 7, 16, 15, 51, 56, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 8, 0, 16, 37, tzinfo=tzoffset(None, 7200))], ['marin.dacos@revues.org', datetime.datetime(2010, 7, 5, 9, 45, 15, tzinfo=tzoffset(None, 3600)), datetime.datetime(2011, 7, 16, 14, 58, 47, tzinfo=tzoffset(None, 7200))]], 'jerome valluy': [['jerome.valluy@univ-paris1.fr', datetime.datetime(2017, 6, 13, 19, 7, 46, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 13, 18, 57, 33, tzinfo=tzoffset(None, 3600))]], 'cl\\xc3\\xa9mence jacquot': [['clemence.jacquot@gmail.com', datetime.datetime(2018, 3, 12, 15, 15, 16, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 15, 15, 16, tzinfo=tzoffset(None, 3600))]], 'stefanev': [['stefanev@club-internet.fr', datetime.datetime(2012, 7, 26, 18, 39, 41, tzinfo=tzlocal()), datetime.datetime(2012, 7, 26, 18, 39, 41, tzinfo=tzlocal())]], 'dumouchel suzanne': [['dumouchelsuzanne@yahoo.fr', datetime.datetime(2017, 6, 16, 7, 39, 48, tzinfo=tzutc()), datetime.datetime(2018, 3, 29, 6, 51, 33, tzinfo=tzutc())]], 'elina leblanc': [['elinaleblanc3007@gmail.com', datetime.datetime(2016, 7, 26, 16, 20, 6, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 26, 16, 20, 6, tzinfo=tzoffset(None, 7200))]], 'emmanuelle duwez': [['emmanuelle.duwez@sciencespo.fr', datetime.datetime(2015, 7, 10, 18, 33, 17, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 10, 18, 33, 17, tzinfo=tzoffset(None, 7200))]], 'laurence rageot': [['laurence.rageot@univ-tours.fr', datetime.datetime(2015, 7, 8, 15, 10, 16, tzinfo=tzlocal()), datetime.datetime(2018, 3, 12, 13, 45, 47, tzinfo=tzlocal())]], 'antoine courtin': [['antoine.courtin@mac.com', datetime.datetime(2013, 7, 12, 20, 19, 16, tzinfo=tzoffset(None, 7200)), datetime.datetime(2017, 6, 9, 22, 38, 49, tzinfo=tzoffset(None, 7200))]], 'johann holland': [['johann.holland@campus-condorcet.fr', datetime.datetime(2014, 7, 6, 14, 32, 27, tzinfo=tzoffset(None, 7200)), datetime.datetime(2016, 7, 19, 10, 46, 36, tzinfo=tzoffset(None, 7200))]], 'casanova nathalie': [['ncasanova@mmsh.univ-aix.fr', datetime.datetime(2016, 7, 22, 14, 58, 33, tzinfo=tzutc()), datetime.datetime(2016, 7, 22, 14, 58, 33, tzinfo=tzutc())]], 'francesco beretta': [['francesco.beretta@ish-lyon.cnrs.fr', datetime.datetime(2018, 3, 12, 9, 52, 19, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 12, 10, 55, 52, tzinfo=tzoffset(None, 3600))]], 'val\\xc3\\xa9rie beaugiraud': [['valerie.beaugiraud@ens-lyon.fr', datetime.datetime(2015, 7, 9, 11, 42, 23, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 9, 11, 42, 23, tzinfo=tzoffset(None, 7200))]], 'ghislain sillaume': [['ghislain.sillaume@cvce.eu', datetime.datetime(2013, 7, 18, 17, 36, 42, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 18, 17, 36, 42, tzinfo=tzoffset(None, 7200))]], 'h\\xc3\\xa9l\\xc3\\xa8ne de foucaud': [['hdefouca@u-paris10.fr', datetime.datetime(2015, 7, 8, 16, 44, 49, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 8, 16, 44, 49, tzinfo=tzoffset(None, 7200))]], 'aur\\xc3\\xa9lien berra': [['aurelien.berra@gmail.com', datetime.datetime(2013, 7, 5, 14, 14, 20, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 23, 9, 48, 3, tzinfo=tzoffset(None, 3600))]], 'ekergosien': [['eric.kergosien@univ-lille3.fr', datetime.datetime(2017, 6, 17, 13, 52, 49, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 12, 15, 18, 57, tzinfo=tzoffset(None, 3600))]], 'j\\xc3\\xa9r\\xc3\\xb4me darmont': [['jerome.darmont@univ-lyon2.fr', datetime.datetime(2018, 3, 9, 11, 17, 31, tzinfo=tzlocal()), datetime.datetime(2018, 3, 9, 11, 17, 31, tzinfo=tzlocal())]], 'cecile rodrigues': [['cecile.rodrigues@cnrs.fr', datetime.datetime(2018, 3, 9, 14, 10, 27, tzinfo=tzoffset(None, 3600)), datetime.datetime(2018, 3, 9, 14, 10, 27, tzinfo=tzoffset(None, 3600))]], 'florence andreacola': [['florence.andreacola@univ-grenoble-alpes.fr', datetime.datetime(2018, 3, 2, 11, 55, 28, tzinfo=tzlocal()), datetime.datetime(2018, 3, 2, 11, 55, 28, tzinfo=tzlocal())]], 'cynthia pedroja': [['cynthia.pedroja@meshs.fr', datetime.datetime(2014, 7, 17, 14, 42, 17, tzinfo=tzoffset(None, 7200)), datetime.datetime(2014, 7, 17, 14, 42, 17, tzinfo=tzoffset(None, 7200))]], 'epler, jakob': [['jakob.epler@dariah.eu', datetime.datetime(2018, 3, 14, 14, 36, 16, tzinfo=tzutc()), datetime.datetime(2018, 3, 14, 14, 36, 16, tzinfo=tzutc())]], 'st\\xc3\\xa9phane pouyllau': [['stephane.pouyllau@cnrs.fr', datetime.datetime(2013, 7, 5, 10, 28, 47, tzinfo=tzoffset(None, 7200)), datetime.datetime(2013, 7, 18, 11, 56, 40, tzinfo=tzoffset(None, 7200))], ['stephane.pouyllau@huma-num.fr', datetime.datetime(2013, 7, 5, 10, 46, 22, tzinfo=tzoffset(None, 7200)), datetime.datetime(2018, 3, 12, 14, 59, 27, tzinfo=tzoffset(None, 3600))]], 'arno.zucker@gmail.com': [['arno.zucker@gmail.com', datetime.datetime(2015, 7, 5, 9, 38, 43, tzinfo=tzoffset(None, 7200)), datetime.datetime(2015, 7, 5, 9, 38, 43, tzinfo=tzoffset(None, 7200))]], 'marionlame@gmail.com': [['marionlame@gmail.com', datetime.datetime(2011, 7, 18, 11, 1, tzinfo=tzoffset(None, 7200)), datetime.datetime(2011, 7, 18, 11, 1, tzinfo=tzoffset(None, 7200))]]}\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "def read_corpus_and_extract_names_2(corpus,liste_noms_and_dups):\n",
    "    liste_noms=liste_noms_and_dups[0]\n",
    "    dups=liste_noms_and_dups[1]\n",
    "    dict_noms={}\n",
    "    tmp_dups_dict={}\n",
    "    tmp_dups_list=[]\n",
    "    for dup in dups:\n",
    "        dupA=dup[0]\n",
    "        dupAnom=dup[0][0]\n",
    "        dupAmail=dup[0][1]\n",
    "        dupAdatemin=None\n",
    "        dupAdatemax=None\n",
    "        for mesg in corpus:\n",
    "            #TEST MIN DATE\n",
    "            [x.lower() for x in corpus[mesg]['mail_auteur']]\n",
    "            if corpus[mesg]['mail_auteur']==dupAmail:\n",
    "                if dupAdatemin is not None:\n",
    "                    if corpus[mesg]['date']<dupAdatemin:\n",
    "                        #print corpus[mesg]['date']\n",
    "                        dupAdatemin=corpus[mesg]['date']\n",
    "                else: dupAdatemin=corpus[mesg]['date']\n",
    "             #TEST MAX DATE       \n",
    "            if corpus[mesg]['mail_auteur']==dupAmail:\n",
    "                if dupAdatemax is not None:\n",
    "                    if corpus[mesg]['date']>dupAdatemax:\n",
    "                        #print corpus[mesg]['date']\n",
    "                        dupAdatemax=corpus[mesg]['date']\n",
    "                else: dupAdatemax=corpus[mesg]['date']   \n",
    "        \n",
    "        \n",
    "        dupB=dup[1]\n",
    "        dupBnom=dup[1][0]\n",
    "        dupBmail=dup[1][1]\n",
    "        dupBdatemin=None\n",
    "        dupBdatemax=None\n",
    "        \n",
    "        #TO TEST LATER WITH LIST_OF_NAMES_IN_ORDER_NOT_TO_ADD_DUPS_MULTIPLE_TIMES\n",
    "        if dupAnom not in tmp_dups_list:\n",
    "            tmp_dups_list.append(dupAnom)\n",
    "        if dupBnom not in tmp_dups_list:\n",
    "            tmp_dups_list.append(dupBnom)\n",
    "        for mesg in corpus:\n",
    "            #TEST MIN DATE\n",
    "            if corpus[mesg]['mail_auteur']==dupBmail:\n",
    "                if dupBdatemin is not None:\n",
    "                    if corpus[mesg]['date']<dupBdatemin:\n",
    "                        #print corpus[mesg]['date']\n",
    "                        dupBdatemin=corpus[mesg]['date']\n",
    "                else: dupBdatemin=corpus[mesg]['date']\n",
    "             #TEST MAX DATE       \n",
    "            if corpus[mesg]['mail_auteur']==dupBmail:\n",
    "                if dupBdatemax is not None:\n",
    "                    if corpus[mesg]['date']>dupBdatemax:\n",
    "                        #print corpus[mesg]['date']\n",
    "                        dupBdatemax=corpus[mesg]['date']\n",
    "                else: dupBdatemax=corpus[mesg]['date'] \n",
    "        #print dupAmail,\" \",dupAdatemin,\"/\",dupAdatemax,\"\\n\",dupBmail,\" \",dupBdatemin,\"/\",dupBdatemax,\"\\n\"\n",
    "        if bool(tmp_dups_dict)== False:\n",
    "            tmp_dups_dict[dupAnom]=[[dupAmail,dupAdatemin,dupAdatemax],[dupBmail,dupBdatemin,dupBdatemax]]\n",
    "\n",
    "            init=1\n",
    "            \n",
    "        if dupAnom not in tmp_dups_dict and init !=1:\n",
    "            #CHECK PRINT\n",
    "            #print dupAnom,\"NOT IN\\n\",tmp_dups_dict\n",
    "            \n",
    "            tmp_dups_dict_tmp= dict.copy(tmp_dups_dict)\n",
    "            for key in tmp_dups_dict_tmp:\n",
    "                #print key\n",
    "                \n",
    "                if SequenceMatcher(None, dupAnom, key).ratio() <0.9:\n",
    "                    tmp_dups_dict[dupAnom]=[[dupAmail,dupAdatemin,dupAdatemax],[dupBmail,dupBdatemin,dupBdatemax]]\n",
    "                else: \n",
    "                    #print \"HEERE\"\n",
    "                    tmp_dups_dict[key].append([[dupAmail,dupAdatemin,dupAdatemax],[dupBmail,dupBdatemin,dupBdatemax]])\n",
    "        else:\n",
    "            \n",
    "            if init !=1:\n",
    "                #print \"HERE\"\n",
    "                tmp_dups_dict[dupAnom].append([[dupAmail,dupAdatemin,dupAdatemax],[dupBmail,dupBdatemin,dupBdatemax]])\n",
    "        init=0\n",
    "    \n",
    "    #print     tmp_dups_dict\n",
    "    tmp_nom_dict={}\n",
    "    \n",
    "    for nom in liste_noms:\n",
    "        \n",
    "        if nom[0] not in tmp_dups_list:\n",
    "            if nom[0] in tmp_nom_dict:\n",
    "                print \"BUG NOMS\"\n",
    "                break\n",
    "            else:\n",
    "                nomdatemin=None\n",
    "                nomdatemax=None\n",
    "                for mesg in corpus:\n",
    "            #TEST MIN DATE\n",
    "                    if corpus[mesg]['mail_auteur']==nom[1]:\n",
    "                        if nomdatemin is not None:\n",
    "                            if corpus[mesg]['date']<nomdatemin:\n",
    "                                #print corpus[mesg]['date']\n",
    "                                nomdatemin=corpus[mesg]['date']\n",
    "                        else: nomdatemin=corpus[mesg]['date']\n",
    "                     #TEST MAX DATE       \n",
    "                    if corpus[mesg]['mail_auteur']==nom[1]:\n",
    "                        if nomdatemax is not None:\n",
    "                            if corpus[mesg]['date']>nomdatemax:\n",
    "                                #print corpus[mesg]['date']\n",
    "                                nomdatemax=corpus[mesg]['date']\n",
    "                        else: nomdatemax=corpus[mesg]['date']\n",
    "                \n",
    "                tmp_nom_dict[nom[0]]=[[nom[1],nomdatemin,nomdatemax]]\n",
    "                #print nom[0],\" \",nom[1],\" \",nomdatemin,\"/\",nomdatemax,\"\\n\"\n",
    "                if bool(tmp_nom_dict)== False:\n",
    "                    tmp_nom_dict[nom[0]]=[[nom[1],nomdatemin,nomdatemax]]\n",
    "\n",
    "    #print  tmp_dups_dict,\"\\n_________________\\n\",tmp_nom_dict,'\\n____________________________\\n'    \n",
    "    dict_noms_parses_dedoub_avec_date= tmp_dups_dict.copy()\n",
    "    dict_noms_parses_dedoub_avec_date.update(tmp_nom_dict)\n",
    "    print dict_noms_parses_dedoub_avec_date\n",
    "    return dict_noms_parses_dedoub_avec_date\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "dict_noms_mails_debut_fin=read_corpus_and_extract_names_2(corpus_mails_DH,liste_noms_and_dups)   \n",
    "print len(dict_noms_mails_debut_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open('dict_noms_mails_debut_fin.obj', 'wb') as handle:\n",
    "    pickle.dump(dict_noms_mails_debut_fin, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dict_noms_mails_debut_fin.obj', 'rb') as handle:\n",
    "    dict_noms_mails_debut_fin = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mehdi.khamassi@upmc.fr\n",
      "upmc.fr\n",
      "dh@cru.fr\n",
      "cru.fr\n",
      "isabelle.thiebau@univ-lille2.fr\n",
      "univ-lille2.fr\n",
      "dh@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "colette.cadiou@irstea.fr\n",
      "irstea.fr\n",
      "claire.clivaz@sib.swiss\n",
      "sib.swiss\n",
      "johann.holland@campus-condorcet.fr\n",
      "campus-condorcet.fr\n",
      "christine.michel@insa-lyon.fr\n",
      "insa-lyon.fr\n",
      "cerisier@univ-poitiers.fr\n",
      "univ-poitiers.fr\n",
      "marjorie.burghart@ehess.fr\n",
      "ehess.fr\n",
      "tei-fr@cru.fr\n",
      "cru.fr\n",
      "stephane.loret@univ-nantes.fr\n",
      "univ-nantes.fr\n",
      "quanti@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "rbdd@services.cnrs.fr\n",
      "services.cnrs.fr\n",
      "stephane.pouyllau@huma-num.fr\n",
      "huma-num.fr\n",
      "formation.continue@enc-sorbonne.fr\n",
      "enc-sorbonne.fr\n",
      "elenagonzalezblanco@yahoo.es\n",
      "yahoo.es\n",
      "humanist@lists.digitalhumanities.org\n",
      "lists.digitalhumanities.org\n",
      "globaloutlookdh-l@uleth.ca\n",
      "uleth.ca\n",
      "digitalclassicist@jiscmail.ac.uk\n",
      "jiscmail.ac.uk\n",
      "dm-l@uleth.ca\n",
      "uleth.ca\n",
      "dhd@mailman.rrz.uni-hamburg.de\n",
      "mailman.rrz.uni-hamburg.de\n",
      "aiucd-l@humnet.unipi.it\n",
      "humnet.unipi.it\n",
      "air-l@aoir.org\n",
      "aoir.org\n",
      "institute@lists.uvic.ca\n",
      "lists.uvic.ca\n",
      "tei-l@listserv.brown.edu\n",
      "listserv.brown.edu\n",
      "humanist-l@uleth.ca\n",
      "uleth.ca\n",
      "centernet@lists.digitalhumanities.org\n",
      "lists.digitalhumanities.org\n",
      "dhcarolina@listserv.unc.edu\n",
      "listserv.unc.edu\n",
      "humanidadesdigitais@gmail.com\n",
      "gmail.com\n",
      "website@hastac.org\n",
      "hastac.org\n",
      "southasia-dh@lists.globaloutlookdh.org\n",
      "lists.globaloutlookdh.org\n",
      "air-l@listserv.aoir.org\n",
      "listserv.aoir.org\n",
      "humanisticadh@gmail.com\n",
      "gmail.com\n",
      "caroline.muller@univ-reims.fr\n",
      "univ-reims.fr\n",
      "ncasanova@mmsh.univ-aix.fr\n",
      "mmsh.univ-aix.fr\n",
      "elinaleblanc3007@gmail.com\n",
      "gmail.com\n",
      "frederic.clavert@unil.ch\n",
      "unil.ch\n",
      "julia.bonaccorsi@univ-lyon2.fr\n",
      "univ-lyon2.fr\n",
      "gerald.kembellec@lecnam.net\n",
      "lecnam.net\n",
      "martin.grandjean@unil.ch\n",
      "unil.ch\n",
      "richard.walter@ens.fr\n",
      "ens.fr\n",
      "laurent.romary@inria.fr\n",
      "inria.fr\n",
      "sarah.cadorel@sciencespo.fr\n",
      "sciencespo.fr\n",
      "aurelien.berra@gmail.com\n",
      "gmail.com\n",
      "antoine.courtin@mac.com\n",
      "mac.com\n",
      "m.bourgatte@icp.fr\n",
      "icp.fr\n",
      "aude.da-cruz-lima@mae.u-paris10.fr\n",
      "mae.u-paris10.fr\n",
      "archives-son-audiovisuel@groups.openedition.org\n",
      "groups.openedition.org\n",
      "fatihaidmhand@yahoo.es\n",
      "yahoo.es\n",
      "emilien.ruiz@ehess.fr\n",
      "ehess.fr\n",
      "marin.dacos@openedition.org\n",
      "openedition.org\n",
      "enrico.natale@infoclio.ch\n",
      "infoclio.ch\n",
      "aamonnz@gmail.com\n",
      "gmail.com\n",
      "frederic@clavert.net\n",
      "clavert.net\n",
      "slh@ens-lyon.fr\n",
      "ens-lyon.fr\n",
      "dominique.stutzmann@irht.cnrs.fr\n",
      "irht.cnrs.fr\n",
      "anne-laure.brisac@inha.fr\n",
      "inha.fr\n",
      "jf.omhover@histographe.com\n",
      "histographe.com\n",
      "stefanev@club-internet.fr\n",
      "club-internet.fr\n",
      "marin.dacos@revues.org\n",
      "revues.org\n",
      "serge.noiret@eui.eu\n",
      "eui.eu\n",
      "marionlame@gmail.com\n",
      "gmail.com\n",
      "maud.ingarao@ens-lyon.fr\n",
      "ens-lyon.fr\n",
      "schassan@hab.de\n",
      "hab.de\n",
      "c.schoech@gmail.com\n",
      "gmail.com\n",
      "laetitia.bontemps@univ-tours.fr\n",
      "univ-tours.fr\n",
      "jouni.tuominen@helsinki.fi\n",
      "helsinki.fi\n",
      "nicolas.larrousse@huma-num.fr\n",
      "huma-num.fr\n",
      "clarisse_bardiot@mac.com\n",
      "mac.com\n",
      "vial.stephane@gmail.com\n",
      "gmail.com\n",
      "benoit.epron@enssib.fr\n",
      "enssib.fr\n",
      "secardinolivier@yahoo.fr\n",
      "yahoo.fr\n",
      "adherents-aipu-fr@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "afec-info@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "anstia-adherents@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "debuter-en-dh@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "emploi-fle@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "delegue.general@adbu.fr\n",
      "adbu.fr\n",
      "helene.coste@univ-lehavre.fr\n",
      "univ-lehavre.fr\n",
      "valerie.neouze@parisdescartes.fr\n",
      "parisdescartes.fr\n",
      "beauguittelaurent@hotmail.com\n",
      "hotmail.com\n",
      "geotamtam@unil.ch\n",
      "unil.ch\n",
      "martaseve@gmail.com\n",
      "gmail.com\n",
      "eric.kergosien@univ-lille3.fr\n",
      "univ-lille3.fr\n",
      "liste-egc@polytech.univ-nantes.fr\n",
      "polytech.univ-nantes.fr\n",
      "info-ic@listes.irisa.fr\n",
      "listes.irisa.fr\n",
      "magis@imag.fr\n",
      "imag.fr\n",
      "bull-i3@irit.fr\n",
      "irit.fr\n",
      "ln@cines.fr\n",
      "cines.fr\n",
      "liste-proml@lri.fr\n",
      "lri.fr\n",
      "docs-ri@yahoogroupes.fr\n",
      "yahoogroupes.fr\n",
      "marie-laure.massot@ens.fr\n",
      "ens.fr\n",
      "gpansu@gmail.com\n",
      "gmail.com\n",
      "francois.theron@uvsq.fr\n",
      "uvsq.fr\n",
      "humanum-diffusion@listes.huma-num.fr\n",
      "listes.huma-num.fr\n",
      "humanum-veille@listes.huma-num.fr\n",
      "listes.huma-num.fr\n",
      "eveline.wandl-vogt@oeaw.ac.at\n",
      "oeaw.ac.at\n",
      "ahdig@googlegroups.com\n",
      "googlegroups.com\n",
      "textualscholarship@jiscmail.ac.uk\n",
      "jiscmail.ac.uk\n",
      "francoise.paquienseguy@sciencespo-lyon.fr\n",
      "sciencespo-lyon.fr\n",
      "vanessa.juloux@ephe.sorbonne.fr\n",
      "ephe.sorbonne.fr\n",
      "ontologie-patrimoine@services.cnrs.fr\n",
      "services.cnrs.fr\n",
      "marta.materni@gmail.com\n",
      "gmail.com\n",
      "inforsid@listes.insa-lyon.fr\n",
      "listes.insa-lyon.fr\n",
      "jea.herzog@gmail.com\n",
      "gmail.com\n",
      "florent.laroche@ec-nantes.fr\n",
      "ec-nantes.fr\n",
      "camillemonnier33@hotmail.com\n",
      "hotmail.com\n",
      "guillaume.blum@design.ulaval.ca\n",
      "design.ulaval.ca\n",
      "daniel.stoekl@ephe.sorbonne.fr\n",
      "ephe.sorbonne.fr\n",
      "nicolasthelyrennes2@gmail.com\n",
      "gmail.com\n",
      "pabloruizfabo@gmail.com\n",
      "gmail.com\n",
      "alexandre.hocquet@univ-lorraine.fr\n",
      "univ-lorraine.fr\n",
      "stamkou@free.fr\n",
      "free.fr\n",
      "nadine.dardenne@cnrs.fr\n",
      "cnrs.fr\n",
      "jerome.valluy@univ-paris1.fr\n",
      "univ-paris1.fr\n",
      "mkoenig@dhi-paris.fr\n",
      "dhi-paris.fr\n",
      "exploreat@oeaw.ac.at\n",
      "oeaw.ac.at\n",
      "myriam.tazi@sciencespo.fr\n",
      "sciencespo.fr\n",
      "remi.jimenes@gmail.com\n",
      "gmail.com\n",
      "jbcamps@hotmail.com\n",
      "hotmail.com\n",
      "thibault.clerice@enc-sorbonne.fr\n",
      "enc-sorbonne.fr\n",
      "sabine.loudcher@univ-lyon2.fr\n",
      "univ-lyon2.fr\n",
      "sarah.cordonnier@gmail.com\n",
      "gmail.com\n",
      "yosra.ghliss17@gmail.com\n",
      "gmail.com\n",
      "caroline.rossi@univ-grenoble-alpes.fr\n",
      "univ-grenoble-alpes.fr\n",
      "jorge.fins@univ-tours.fr\n",
      "univ-tours.fr\n",
      "huyghe.marie@gmail.com\n",
      "gmail.com\n",
      "laurent.cailly@univ-tours.fr\n",
      "univ-tours.fr\n",
      "carmen.brando@gmail.com\n",
      "gmail.com\n",
      "francesca.frontini@univ-montp3.fr\n",
      "univ-montp3.fr\n",
      "dumouchelsuzanne@yahoo.fr\n",
      "yahoo.fr\n",
      "legram@yahoogroupes.fr\n",
      "yahoogroupes.fr\n",
      "culture.numerique@ml.free.fr\n",
      "ml.free.fr\n",
      "eric.guichard@enssib.fr\n",
      "enssib.fr\n",
      "francoise.blum@univ-paris1.fr\n",
      "univ-paris1.fr\n",
      "beatrice.markhoff@univ-tours.fr\n",
      "univ-tours.fr\n",
      "antonio.casilli@googlemail.com\n",
      "googlemail.com\n",
      "sylvain.laube@univ-brest.fr\n",
      "univ-brest.fr\n",
      "elisabeth.belmas@wanadoo.fr\n",
      "wanadoo.fr\n",
      "projet.iglouvre@gmail.com\n",
      "gmail.com\n",
      "lisette.calderan@inria.fr\n",
      "inria.fr\n",
      "claire.clivaz@unil.ch\n",
      "unil.ch\n",
      "viera.rebolledodhuin@free.fr\n",
      "free.fr\n",
      "michel.bernard@univ-paris3.fr\n",
      "univ-paris3.fr\n",
      "aurelie.olivesi@wanadoo.fr\n",
      "wanadoo.fr\n",
      "diffusion@listes.ancmsp.com\n",
      "listes.ancmsp.com\n",
      "efigies-info@rezo.net\n",
      "rezo.net\n",
      "etudesfeministes-l@simone.univ-tlse2.fr\n",
      "simone.univ-tlse2.fr\n",
      "aurelie.olivesi@univ-lyon1.fr\n",
      "univ-lyon1.fr\n",
      "cecile.soudan@ehess.fr\n",
      "ehess.fr\n",
      "e.salvatori@mediev.unipi.it\n",
      "mediev.unipi.it\n",
      "gregory.grefenstette@inria.fr\n",
      "inria.fr\n",
      "emmanuelguez@yahoo.fr\n",
      "yahoo.fr\n",
      "cecile.boulaire@univ-tours.fr\n",
      "univ-tours.fr\n",
      "tei-fr@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "christine.benevent@univ-tours.fr\n",
      "univ-tours.fr\n",
      "laurent.gerbier@univ-tours.fr\n",
      "univ-tours.fr\n",
      "sandrine.breuil@univ-tours.fr\n",
      "univ-tours.fr\n",
      "michaelesinatra@gmail.com\n",
      "gmail.com\n",
      "ottaviano.nancy@gmail.com\n",
      "gmail.com\n",
      "cynthia.pedroja@meshs.fr\n",
      "meshs.fr\n",
      "iglouvremb@gmail.com\n",
      "gmail.com\n",
      "espejosuros.javier@gmail.com\n",
      "gmail.com\n",
      "pierre.mounier@openedition.org\n",
      "openedition.org\n",
      "antoine.blanchard@gmail.com\n",
      "gmail.com\n",
      "nicole.dufournaud@laposte.net\n",
      "laposte.net\n",
      "jean-daniel.fekete@inria.fr\n",
      "inria.fr\n",
      "listes@ahicf.com\n",
      "ahicf.com\n",
      "oledeuff@gmail.com\n",
      "gmail.com\n",
      "paul.girard@sciencespo.fr\n",
      "sciencespo.fr\n",
      "mahe.annaig@wanadoo.fr\n",
      "wanadoo.fr\n",
      "stephane.pouyllau@cnrs.fr\n",
      "cnrs.fr\n",
      "nicolas.thely@univ-rennes2.fr\n",
      "univ-rennes2.fr\n",
      "ghislain.sillaume@cvce.eu\n",
      "cvce.eu\n",
      "pierre.mounier@ehess.fr\n",
      "ehess.fr\n",
      "nicolas.legrand@obspm.fr\n",
      "obspm.fr\n",
      "alexandre.moatti@mines.org\n",
      "mines.org\n",
      "svhoolan@ulb.ac.be\n",
      "ulb.ac.be\n",
      "marie.e.lescasse@gmail.com\n",
      "gmail.com\n",
      "histoire_eco-request@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "athena@services.cnrs.fr\n",
      "services.cnrs.fr\n",
      "archives-fr@yahoogroupes.fr\n",
      "yahoogroupes.fr\n",
      "nep-his@lists.repec.org\n",
      "lists.repec.org\n",
      "medici@listes.huma-num.fr\n",
      "listes.huma-num.fr\n",
      "ferinterfrance@googlegroups.com\n",
      "googlegroups.com\n",
      "gerald.kembellec@cnam.fr\n",
      "cnam.fr\n",
      "judith.hannoun@univ-amu.fr\n",
      "univ-amu.fr\n",
      "francesco.beretta@ish-lyon.cnrs.fr\n",
      "ish-lyon.cnrs.fr\n",
      "claire.lemercier@sciencespo.fr\n",
      "sciencespo.fr\n",
      "laurence.rageot@univ-tours.fr\n",
      "univ-tours.fr\n",
      "inatheque@ina.fr\n",
      "ina.fr\n",
      "frederic.clavert@uni.lu\n",
      "uni.lu\n",
      "joel.marchand@huma-num.fr\n",
      "huma-num.fr\n",
      "raphaelle.krummeich@univ-rouen.fr\n",
      "univ-rouen.fr\n",
      "stephane.lamasse@univ-paris1.fr\n",
      "univ-paris1.fr\n",
      "anne.baillot@gmail.com\n",
      "gmail.com\n",
      "delphine.cavallo@univ-amu.fr\n",
      "univ-amu.fr\n",
      "adbs-info@listes.adbs.fr\n",
      "listes.adbs.fr\n",
      "accesouvert@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "doccitanist@services.cnrs.fr\n",
      "services.cnrs.fr\n",
      "info-aria@lsis.org\n",
      "lsis.org\n",
      "florence.andreacola@univ-grenoble-alpes.fr\n",
      "univ-grenoble-alpes.fr\n",
      "elodie.faath@openedition.org\n",
      "openedition.org\n",
      "francois.bavaud@unil.ch\n",
      "unil.ch\n",
      "llist@unil.ch\n",
      "unil.ch\n",
      "amelie.vairelles@sciencespo.fr\n",
      "sciencespo.fr\n",
      "recherche.coordination@bnf.fr\n",
      "bnf.fr\n",
      "dh-request@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "adeline.joffres@huma-num.fr\n",
      "huma-num.fr\n",
      "recherche-design@listes.univ-paris1.fr\n",
      "listes.univ-paris1.fr\n",
      "projekt-membres@liste.unimes.fr\n",
      "liste.unimes.fr\n",
      "projekt@unimes.fr\n",
      "unimes.fr\n",
      "info@design-fax.fr\n",
      "design-fax.fr\n",
      "theuth@listes.univ-rennes1.fr\n",
      "listes.univ-rennes1.fr\n",
      "antonio.casilli@ehess.fr\n",
      "ehess.fr\n",
      "graham.ranger@univ-avignon.fr\n",
      "univ-avignon.fr\n",
      "corpora@uib.no\n",
      "uib.no\n",
      "saes@univ-pau.fr\n",
      "univ-pau.fr\n",
      "alaes_liste@yahoogroupes.fr\n",
      "yahoogroupes.fr\n",
      "parislinguists@yahoogroupes.fr\n",
      "yahoogroupes.fr\n",
      "agorantic@listes.univ-avignon.fr\n",
      "listes.univ-avignon.fr\n",
      "pascal.cristofoli@ehess.fr\n",
      "ehess.fr\n",
      "raphaelle.bour@irit.fr\n",
      "irit.fr\n",
      "annael.le-poullennec@psl.eu\n",
      "psl.eu\n",
      "irihs@univ-rouen.fr\n",
      "univ-rouen.fr\n",
      "olfa.lamloum@gmail.com\n",
      "gmail.com\n",
      "pierazzo@gmail.com\n",
      "gmail.com\n",
      "clemence.jacquot@gmail.com\n",
      "gmail.com\n",
      "sclerisse@parisnanterre.fr\n",
      "parisnanterre.fr\n",
      "listesocius@groups.openedition.org\n",
      "groups.openedition.org\n",
      "digit_hum@ens.fr\n",
      "ens.fr\n",
      "florence.clavaud@free.fr\n",
      "free.fr\n",
      "amel.fraisse@univ-lille3.fr\n",
      "univ-lille3.fr\n",
      "jouni.tuominen@aalto.fi\n",
      "aalto.fi\n",
      "georges-xavier.blary@unilim.fr\n",
      "unilim.fr\n",
      "rene.audet@lit.ulaval.ca\n",
      "lit.ulaval.ca\n",
      "jakob.epler@dariah.eu\n",
      "dariah.eu\n",
      "jerome.darmont@univ-lyon2.fr\n",
      "univ-lyon2.fr\n",
      "madics-adoc@listes.univ-lyon2.fr\n",
      "listes.univ-lyon2.fr\n",
      "annonces@madics.fr\n",
      "madics.fr\n",
      "fil-tmd@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "eda-liste@listes.univ-lyon2.fr\n",
      "listes.univ-lyon2.fr\n",
      "gazettebd3@imag.fr\n",
      "imag.fr\n",
      "thierry.poibeau@ens.fr\n",
      "ens.fr\n",
      "dbernhard@unistra.fr\n",
      "unistra.fr\n",
      "sandrine.clerisse@cnrs.fr\n",
      "cnrs.fr\n",
      "txm-users@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "litor@listes.univ-paris3.fr\n",
      "listes.univ-paris3.fr\n",
      "numeruniv-quotidien@cines.fr\n",
      "cines.fr\n",
      "caroline.cance@univ-orleans.fr\n",
      "univ-orleans.fr\n",
      "gresillon@cmb.hu-berlin.de\n",
      "cmb.hu-berlin.de\n",
      "cecile.rodrigues@cnrs.fr\n",
      "cnrs.fr\n",
      "jahjah.marc@gmail.com\n",
      "gmail.com\n",
      "muriel.foulonneau@gmail.com\n",
      "gmail.com\n",
      "arno.zucker@gmail.com\n",
      "gmail.com\n",
      "yamina.bensaadoune@univ-rouen.fr\n",
      "univ-rouen.fr\n",
      "aurelie.olivesi@gmail.com\n",
      "gmail.com\n",
      "pe.barrault@gmail.com\n",
      "gmail.com\n",
      "emmanuelle.duwez@sciencespo.fr\n",
      "sciencespo.fr\n",
      "manuel.zacklad@cnam.fr\n",
      "cnam.fr\n",
      "mathieu.andro@versailles.inra.fr\n",
      "versailles.inra.fr\n",
      "lisa.chupin@gmail.com\n",
      "gmail.com\n",
      "corpus-ecrits@cru.fr\n",
      "cru.fr\n",
      "marie-noelle.polino@ahicf.com\n",
      "ahicf.com\n",
      "clarisse_bardiot@me.com\n",
      "me.com\n",
      "christine.chadier@univ-lyon3.fr\n",
      "univ-lyon3.fr\n",
      "valerie.beaugiraud@ens-lyon.fr\n",
      "ens-lyon.fr\n",
      "laurens@ehess.fr\n",
      "ehess.fr\n",
      "iwetel@listserv.rediris.es\n",
      "listserv.rediris.es\n",
      "infoling@listserv.rediris.es\n",
      "listserv.rediris.es\n",
      "redhd@humanidadesdigitales.net\n",
      "humanidadesdigitales.net\n",
      "spadinielena@gmail.com\n",
      "gmail.com\n",
      "hdefouca@u-paris10.fr\n",
      "u-paris10.fr\n",
      "olivier.marlet@univ-tours.fr\n",
      "univ-tours.fr\n",
      "emmanuelle.morlock@gmail.com\n",
      "gmail.com\n",
      "cahier@groupes.renater.fr\n",
      "groupes.renater.fr\n",
      "audrey.baneyx@sciencespo.fr\n",
      "sciencespo.fr\n",
      "['upmc.fr', 'cru.fr', 'univ-lille2.fr', 'groupes.renater.fr', 'irstea.fr', 'sib.swiss', 'campus-condorcet.fr', 'insa-lyon.fr', 'univ-poitiers.fr', 'ehess.fr', 'univ-nantes.fr', 'services.cnrs.fr', 'huma-num.fr', 'enc-sorbonne.fr', 'yahoo.es', 'lists.digitalhumanities.org', 'uleth.ca', 'jiscmail.ac.uk', 'mailman.rrz.uni-hamburg.de', 'humnet.unipi.it', 'aoir.org', 'lists.uvic.ca', 'listserv.brown.edu', 'listserv.unc.edu', 'gmail.com', 'hastac.org', 'lists.globaloutlookdh.org', 'listserv.aoir.org', 'univ-reims.fr', 'mmsh.univ-aix.fr', 'unil.ch', 'univ-lyon2.fr', 'lecnam.net', 'ens.fr', 'inria.fr', 'sciencespo.fr', 'mac.com', 'icp.fr', 'mae.u-paris10.fr', 'groups.openedition.org', 'openedition.org', 'infoclio.ch', 'clavert.net', 'ens-lyon.fr', 'irht.cnrs.fr', 'inha.fr', 'histographe.com', 'club-internet.fr', 'revues.org', 'eui.eu', 'hab.de', 'univ-tours.fr', 'helsinki.fi', 'enssib.fr', 'yahoo.fr', 'adbu.fr', 'univ-lehavre.fr', 'parisdescartes.fr', 'hotmail.com', 'univ-lille3.fr', 'polytech.univ-nantes.fr', 'listes.irisa.fr', 'imag.fr', 'irit.fr', 'cines.fr', 'lri.fr', 'yahoogroupes.fr', 'uvsq.fr', 'listes.huma-num.fr', 'oeaw.ac.at', 'googlegroups.com', 'sciencespo-lyon.fr', 'ephe.sorbonne.fr', 'listes.insa-lyon.fr', 'ec-nantes.fr', 'design.ulaval.ca', 'univ-lorraine.fr', 'free.fr', 'cnrs.fr', 'univ-paris1.fr', 'dhi-paris.fr', 'univ-grenoble-alpes.fr', 'univ-montp3.fr', 'ml.free.fr', 'googlemail.com', 'univ-brest.fr', 'wanadoo.fr', 'univ-paris3.fr', 'listes.ancmsp.com', 'rezo.net', 'simone.univ-tlse2.fr', 'univ-lyon1.fr', 'mediev.unipi.it', 'meshs.fr', 'laposte.net', 'ahicf.com', 'univ-rennes2.fr', 'cvce.eu', 'obspm.fr', 'mines.org', 'ulb.ac.be', 'lists.repec.org', 'cnam.fr', 'univ-amu.fr', 'ish-lyon.cnrs.fr', 'ina.fr', 'uni.lu', 'univ-rouen.fr', 'listes.adbs.fr', 'lsis.org', 'bnf.fr', 'listes.univ-paris1.fr', 'liste.unimes.fr', 'unimes.fr', 'design-fax.fr', 'listes.univ-rennes1.fr', 'univ-avignon.fr', 'uib.no', 'univ-pau.fr', 'listes.univ-avignon.fr', 'psl.eu', 'parisnanterre.fr', 'aalto.fi', 'unilim.fr', 'lit.ulaval.ca', 'dariah.eu', 'listes.univ-lyon2.fr', 'madics.fr', 'unistra.fr', 'listes.univ-paris3.fr', 'univ-orleans.fr', 'cmb.hu-berlin.de', 'versailles.inra.fr', 'me.com', 'univ-lyon3.fr', 'listserv.rediris.es', 'humanidadesdigitales.net', 'u-paris10.fr']\n",
      "\n",
      "______________\n",
      "upmc.fr \n",
      "\n",
      "\n",
      "______________\n",
      "cru.fr \n",
      "\n",
      "\n",
      "______________\n",
      "univ-lille2.fr \n",
      "\n",
      "\n",
      "______________\n",
      "groupes.renater.fr \n",
      "\n",
      "\n",
      "______________\n",
      "irstea.fr \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_locations_from_email_adresses(liste_mails):\n",
    "    import whois\n",
    "    import time\n",
    "    \n",
    " ###ON EXTRAIT LES DOMAINES_MAILS_ET_ON_VA_RECHERCHER_UNE_LOCALISATION_A_PARTIR_DE_CELA\n",
    "###CE PROGRAMME EST EN DEUX PARTIES CAR ON DOIT D ABORD EXTRAIT LA LISTE DE WHOIS QUI LIMIT LE NOMBRE DE RESULTATS,\n",
    "###ON ITERE DONC SUR UNE BOUCLE DE REMPLISSAGE D'UN DICT QU'ON RENVOIE, QU'ON PARSERA ENSUITE\n",
    "    liste_domaines=[]\n",
    "    #print liste_mails\n",
    "    for key in  liste_mails:\n",
    "        print key\n",
    "        #print dict_noms[key]\n",
    "        print str(key.split(\"@\")[1:][0]).lower()\n",
    "        if str(key.split(\"@\")[1:][0].lower()) not in liste_domaines:\n",
    "                    liste_domaines.append(key.split(\"@\")[1:][0].lower())\n",
    "            \n",
    "    print liste_domaines\n",
    "    dict_infos_domaines={}\n",
    "    for domaine in liste_domaines:\n",
    "        attempt=0\n",
    "        not_localised=[]\n",
    "        while True:\n",
    "            try :\n",
    "                if domaine not in dict_infos_domaines:\n",
    "                    \n",
    "                    infos_domaine = whois.whois(domaine)\n",
    "                    print \"\\n______________\\n\",domaine,\"\\n\"#,infos_domaine\n",
    "                    dict_infos_domaines[domaine]=infos_domaine\n",
    "                    time.sleep(4)\n",
    "                    \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                attempt+=1\n",
    "                time.sleep(15)\n",
    "                print \"ONE BREAK\"\n",
    "                #print e\n",
    "                if attempt < 5:\n",
    "                    continue\n",
    "                else:\n",
    "                    not_localised.append(domaine)\n",
    "                    break\n",
    "            break\n",
    "    print dict_infos_domaines\n",
    "    print not_localised\n",
    "    return [dict_infos_domaines,not_localised]\n",
    "            \n",
    "\n",
    "    \n",
    "        \n",
    "list_localisations=extract_locations_from_email_adresses(liste_de_tous_les_mails)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ON SAUVEGARDE LES DONNNES EXTRAITES\n",
    "import pickle\n",
    "\n",
    "filehandler = open(b\"list_localisations.obj\",\"wb\")\n",
    "pickle.dump(list_localisations,filehandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'list_localisations.obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-42c57075edc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_localisations.obj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlist_localisations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'list_localisations.obj'"
     ]
    }
   ],
   "source": [
    "###ON LES RECUPERE\n",
    "import pickle\n",
    "\n",
    "\n",
    "file = open(\"list_localisations.obj\",'rb')\n",
    "list_localisations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ-orleans.fr\n",
      "univ-orleans.fr\n",
      "design.ulaval.ca\n",
      "design.ulaval.ca\n",
      "inha.fr\n",
      "inha.fr\n",
      "me.com\n",
      "me.com \"1 Infinite Loop\" \"Cupertino\" \"CA\" \"US\"\n",
      "dariah.eu\n",
      "dariah.eu\n",
      "cnam.fr\n",
      "cnam.fr\n",
      "lecnam.net\n",
      "lecnam.net \"Rue des Cray\\ufffdres, BP 1034\" \"reims\" null \"FR\"\n",
      "univ-nantes.fr\n",
      "univ-nantes.fr\n",
      "mae.u-paris10.fr\n",
      "mae.u-paris10.fr\n",
      "irit.fr\n",
      "irit.fr\n",
      "univ-brest.fr\n",
      "univ-brest.fr\n",
      "univ-lorraine.fr\n",
      "univ-lorraine.fr\n",
      "icp.fr\n",
      "icp.fr\n",
      "oeaw.ac.at\n",
      "oeaw.ac.at \"Dr. Ignaz Seipel-Platz 2\" \"Wien\" \"Austria\"\n",
      "u-paris10.fr\n",
      "u-paris10.fr\n",
      "inria.fr\n",
      "inria.fr\n",
      "enc-sorbonne.fr\n",
      "enc-sorbonne.fr\n",
      "univ-amu.fr\n",
      "univ-amu.fr\n",
      "sciencespo-lyon.fr\n",
      "sciencespo-lyon.fr\n",
      "univ-tours.fr\n",
      "univ-tours.fr\n",
      "univ-rouen.fr\n",
      "univ-rouen.fr\n",
      "univ-reims.fr\n",
      "univ-reims.fr\n",
      "campus-condorcet.fr\n",
      "campus-condorcet.fr\n",
      "clavert.net\n",
      "clavert.net \"Obfuscated whois Gandi-63-65 boulevard Massena\" \"Obfuscated whois Gandi-Paris\" \"Paris\" \"FR\"\n",
      "ehess.fr\n",
      "ehess.fr\n",
      "univ-paris1.fr\n",
      "univ-paris1.fr\n",
      "unistra.fr\n",
      "unistra.fr\n",
      "yahoo.es\n",
      "yahoo.es null null null null\n",
      "univ-lyon3.fr\n",
      "univ-lyon3.fr\n",
      "revues.org\n",
      "revues.org [\n",
      "    \"Marin Dacos\", \n",
      "    \"60 rue Jean-Baptiste Brunel\", \n",
      "    \"AVIGNON, FRANCE 84000\", \n",
      "    \"Marin Dacos 60 rue Jean-Baptiste Brunel AVIGNON, FRANCE 84000\"\n",
      "  ] \"Avignon\" null \"FR\"\n",
      "sciencespo.fr\n",
      "sciencespo.fr\n",
      "mac.com\n",
      "mac.com \"1 Infinite Loop\" \"Cupertino\" \"CA\" \"US\"\n",
      "irht.cnrs.fr\n",
      "irht.cnrs.fr\n",
      "univ-grenoble-alpes.fr\n",
      "univ-grenoble-alpes.fr\n",
      "unilim.fr\n",
      "unilim.fr\n",
      "meshs.fr\n",
      "meshs.fr\n",
      "ec-nantes.fr\n",
      "ec-nantes.fr\n",
      "infoclio.ch\n",
      "infoclio.ch\n",
      "adbu.fr\n",
      "adbu.fr\n",
      "cnrs.fr\n",
      "cnrs.fr\n",
      "histographe.com\n",
      "histographe.com \"office #10730740, c/o OwO, BP80157\" \"Roubaix Cedex 1\" null \"FR\"\n",
      "ulb.ac.be\n",
      "ulb.ac.be\n",
      "hotmail.com\n",
      "hotmail.com \"One Microsoft Way,\" \"Redmond\" \"WA\" \"US\"\n",
      "psl.eu\n",
      "psl.eu\n",
      "club-internet.fr\n",
      "club-internet.fr\n",
      "openedition.org\n",
      "openedition.org [\n",
      "    \"CLEO CNRS UMS 3287,\", \n",
      "    \"22, rue John Maynard Keynes, BAT C\"\n",
      "  ] \"Marseille\" null \"FR\"\n",
      "googlemail.com\n",
      "googlemail.com \"1600 Amphitheatre Parkway,\" \"Mountain View\" \"CA\" \"US\"\n",
      "upmc.fr\n",
      "upmc.fr\n",
      "univ-avignon.fr\n",
      "univ-avignon.fr\n",
      "EUI.eu\n",
      "EUI.eu\n",
      "aalto.fi\n",
      "aalto.fi [\n",
      "    \"Viestint\\ufffd/Nina Saarimaa\", \n",
      "    \"PL 17800\", \n",
      "    \"00076\", \n",
      "    \"AALTO\"\n",
      "  ]\n",
      "univ-paris3.fr\n",
      "univ-paris3.fr\n",
      "cmb.hu-berlin.de\n",
      "cmb.hu-berlin.de [\n",
      "    \"Humboldt-Universitaet zu Berlin\", \n",
      "    \"ZE Computer- und Medienservice\", \n",
      "    \"Unter den Linden 6\"\n",
      "  ] \"Berlin\" {\n",
      "  \"status\": \"connect\"\n",
      "gmail.com\n",
      "gmail.com \"1600 Amphitheatre Parkway,\" \"Mountain View\" \"CA\" \"US\"\n",
      "free.fr\n",
      "free.fr\n",
      "enssib.fr\n",
      "enssib.fr\n",
      "versailles.inra.fr\n",
      "versailles.inra.fr\n",
      "insa-lyon.fr\n",
      "insa-lyon.fr\n",
      "helsinki.fi\n",
      "helsinki.fi [\n",
      "    \"Tietotekniikkakeskus / tietoliikenneryhm\\ufffd\", \n",
      "    \"PL 28 (Koetilantie 7)\", \n",
      "    \"00014\", \n",
      "    \"Helsingin yliopisto\"\n",
      "  ]\n",
      "huma-num.fr\n",
      "huma-num.fr\n",
      "univ-lyon2.fr\n",
      "univ-lyon2.fr\n",
      "ens.fr\n",
      "ens.fr\n",
      "univ-rennes2.fr\n",
      "univ-rennes2.fr\n",
      "cvce.eu\n",
      "cvce.eu\n",
      "ina.fr\n",
      "ina.fr\n",
      "uni.lu\n",
      "uni.lu null null null null\n",
      "dhi-paris.fr\n",
      "dhi-paris.fr\n",
      "univ-lille3.fr\n",
      "univ-lille3.fr\n",
      "ish-lyon.cnrs.fr\n",
      "ish-lyon.cnrs.fr\n",
      "lit.ulaval.ca\n",
      "lit.ulaval.ca\n",
      "mines.org\n",
      "mines.org [\n",
      "    \"Ecole Mines ParisTech\", \n",
      "    \"60 Boulevard Saint-Michel\"\n",
      "  ] \"Paris\" null \"FR\"\n",
      "irstea.fr\n",
      "irstea.fr\n",
      "univ-lille2.fr\n",
      "univ-lille2.fr\n",
      "ephe.sorbonne.fr\n",
      "ephe.sorbonne.fr\n",
      "uvsq.fr\n",
      "uvsq.fr\n",
      "yahoo.fr\n",
      "yahoo.fr\n",
      "wanadoo.fr\n",
      "wanadoo.fr\n",
      "ens-lyon.fr\n",
      "ens-lyon.fr\n",
      "mmsh.univ-aix.fr\n",
      "mmsh.univ-aix.fr\n",
      "bnf.fr\n",
      "bnf.fr\n",
      "mediev.unipi.it\n",
      "mediev.unipi.it\n",
      "parisnanterre.fr\n",
      "parisnanterre.fr\n",
      "obspm.fr\n",
      "obspm.fr\n",
      "unil.ch\n",
      "unil.ch\n",
      "ahicf.com\n",
      "ahicf.com \"9 rue du Ch\\u00e2teau-Landon\" \"Paris\" null \"FR\"\n"
     ]
    }
   ],
   "source": [
    "###LES INFOS RECUPEREES DEPUIS WHOIS SONT MALFORMEES,ON NE PEUT LES CONVERTIR EN DICT PROPRE, IL FAUT DONC LES PARSER AVEC UN PARSEUR \"MAISON\"\n",
    "#print list_localisations[0]\n",
    "\n",
    "\n",
    "def extract_locations_from_email_adresses_2(dict_loc):\n",
    "    list_locs=[]\n",
    "   \n",
    "    for loc in dict_loc:\n",
    "        print loc\n",
    "        #print str(dict_loc[loc])\n",
    "        address_field=None\n",
    "        city_field=None\n",
    "        state_field=None\n",
    "        country_field=None\n",
    "        loc_full_string=\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"address\" in  str(dict_loc[loc]):\n",
    "            \n",
    "            address_field= re.sub(r'.*\\\"address\\\": ','',str(dict_loc[loc]),flags=re.DOTALL)\n",
    "            sep = \", \\n  \\\"\"\n",
    "            address_field = address_field.split(sep, 1)[0]\n",
    "            #print address_field,\"\\n\"\n",
    "        #else:\n",
    "            #print \"NO ADDRESS FIELD\\n\"\n",
    "        \n",
    "        if \"city\" in  str(dict_loc[loc]):\n",
    "            \n",
    "            city_field= re.sub(r'.*\\\"city\\\": ','',str(dict_loc[loc]),flags=re.DOTALL)\n",
    "            sep = \", \\n  \\\"\"\n",
    "            city_field = city_field.split(sep, 1)[0]\n",
    "            #print city_field,\"\\n\"\n",
    "        #else:\n",
    "            #print \"NO city FIELD\\n\"\n",
    "            \n",
    "        if \"state\" in  str(dict_loc[loc]):\n",
    "            \n",
    "            state_field= re.sub(r'.*\\\"state\\\": ','',str(dict_loc[loc]),flags=re.DOTALL)\n",
    "            sep = \", \\n  \\\"\"\n",
    "            state_field = state_field.split(sep, 1)[0]\n",
    "            #print state_field,\"\\n\"\n",
    "        #else:\n",
    "            #print \"NO state FIELD\\n\"    \n",
    "            \n",
    "        \n",
    "            \n",
    "        if \"country\" in  str(dict_loc[loc]):\n",
    "            \n",
    "            country_field= re.sub(r'.*\\\"country\\\": ','',str(dict_loc[loc]),flags=re.DOTALL)\n",
    "            sep = \", \\n  \\\"\"\n",
    "            country_field = country_field.split(sep, 1)[0]\n",
    "            #print country_field,\"\\n\"\n",
    "        #else:\n",
    "            #print \"NO country FIELD\\n\"\n",
    "            \n",
    "        # on concatene le tout, qu'on passera à geopy pour identifier des addresses\n",
    "        loc_full_string=loc\n",
    "        if address_field is not None :\n",
    "            loc_full_string+=\" \"+address_field\n",
    "        if  city_field is not None:\n",
    "            loc_full_string+=\" \"+city_field\n",
    "            \n",
    "        if  state_field is not None:\n",
    "            loc_full_string+=\" \"+state_field\n",
    "        if  country_field is not None:\n",
    "            \n",
    "            loc_full_string+=\" \"+country_field\n",
    "        print loc_full_string\n",
    "        list_locs.append([loc,loc_full_string])\n",
    "    \n",
    "    return list_locs\n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "list_loc_with_whois=extract_locations_from_email_adresses_2(list_localisations[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_geocodes_from_list_loc(lists_locs_aff):\n",
    "#FOR OSM API\n",
    "    from geopy.geocoders import Nominatim\n",
    "    import time\n",
    "    import os\n",
    "    import os.path\n",
    "    import pickle\n",
    "    \n",
    "    \n",
    "#FOR GOOGLE API \n",
    "    from geopy.geocoders import GoogleV3\n",
    "    \n",
    "    my_api_key = os.environ.get('MY_API_KEY', None)\n",
    "    \n",
    "    print my_api_key\n",
    "    \n",
    "    \n",
    "    loc_dict={}\n",
    "    #need to export export MY_API_KEY=\"\" from terminal\n",
    "    google_maps = GoogleV3(api_key=my_api_key,domain='maps.google.fr')\n",
    "    for loc_af in lists_locs_aff:\n",
    "        \n",
    "        loc_aff=loc_af[1].replace('\\\"',\" \").replace(\"[\",\"\").replace(\"]\",\"\").replace(\" null \", \" \").replace(\",\",\" \").replace(\"\\\\ufffd\",\"è\")\n",
    "        loc_name=loc_af[0]\n",
    "        \n",
    "        if os.path.exists(\"./geocod_tmp_obj/\"+loc_name+\".obj\")==True:\n",
    "            with open(\"./geocod_tmp_obj/\"+loc_name+\".obj\", 'rb') as handle:\n",
    "                location = pickle.load(handle)\n",
    "                loc_dict[loc_name]=location\n",
    "                \n",
    "        else:        \n",
    "            print loc_aff\n",
    "                #geolocator = Nominatim()\n",
    "                #location = geolocator.geocode(loc_aff)\n",
    "\n",
    "            location=google_maps.geocode(loc_aff,\"exactly_one=True\")\n",
    "            try:\n",
    "                        print location.raw\n",
    "                        #time.sleep(1)\n",
    "                        loc_dict[loc_name]=location.raw\n",
    "                        \n",
    "\n",
    "                        filehandler = open(\"./geocod_tmp_obj/\"+loc_name+\".obj\",\"wb\")\n",
    "                        pickle.dump(location.raw,filehandler)\n",
    "\n",
    "            except :\n",
    "                        loc_dict[loc_name]=\"TO8BE8MANUALLY8EDITED\"\n",
    "        \n",
    "            \n",
    "  \n",
    "        \n",
    "        \n",
    "    \n",
    "                \n",
    "             \n",
    "        \n",
    "    \n",
    "    return loc_dict\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "geocoded_locs=retrieve_geocodes_from_list_loc(list_loc_with_whois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open('geocoded_locs.obj', 'wb') as handle:\n",
    "    pickle.dump(geocoded_locs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('geocoded_locs.obj', 'rb') as handle:\n",
    "    geocoded_locs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print geocoded_locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RETRIEVE THE  LOCATION DATAS THAT NEED TO BE MANUALLY EDITED\n",
    "#\"TO8BE8MANUALLY8EDITED\"\n",
    "def extract_fields_requiring_manual_intervention(geocoded_locs):\n",
    "    fields_needing_manual_geoloc=[]\n",
    "    for loc in geocoded_locs:\n",
    "\n",
    "        print loc\n",
    "        print geocoded_locs[loc]\n",
    "        if geocoded_locs[loc]==\"TO8BE8MANUALLY8EDITED\":\n",
    "            fields_needing_manual_geoloc.append(loc)\n",
    "    return fields_needing_manual_geoloc\n",
    "\n",
    "\n",
    "location_needing_manual_intervention=extract_fields_requiring_manual_intervention(geocoded_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lecnam.net', 'ahicf.com', 'clavert.net', 'yahoo.es', 'infoclio.ch', 'adbu.fr', 'histographe.com', 'openedition.org', 'aalto.fi', 'gmail.com', 'helsinki.fi', 'uni.lu', 'revues.org']\n"
     ]
    }
   ],
   "source": [
    "##AND EXPORT IT TO CSV\n",
    "print location_needing_manual_intervention\n",
    "import csv\n",
    "\n",
    "with open(\"./CSVs_for_manual_fixing/location_refining.csv\", 'wb') as myfile:\n",
    "    \n",
    "    rows = zip(location_needing_manual_intervention)\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for row in rows:\n",
    "            wr.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'lecnam.net': {u'geometry': {u'location': {u'lat': '48.8667495', u'lng': '2.3532426'}}}, u'histographe.com': {u'geometry': {u'location': {u'lat': '48.8667495', u'lng': '2.3532426'}}}, u'revues.org': {u'geometry': {u'location': {u'lat': '43.3430737', u'lng': '5.4328468'}}}, u'adbu.fr': {u'geometry': {u'location': {u'lat': '48.8440177', u'lng': '2.3374428'}}}, u'clavert.net': {u'geometry': {u'location': {u'lat': '46.5210932', u'lng': '6.5779719'}}}, u'openedition.org': {u'geometry': {u'location': {u'lat': '43.3430737', u'lng': '5.4328468'}}}, u'yahoo.es': {u'geometry': {u'location': {u'lat': 45.766883438059835, u'lng': 2.5993781799139635}}}, u'helsinki.fi': {u'geometry': {u'location': {u'lat': '60.1779949', u'lng': '24.8543427'}}}, u'aalto.fi': {u'geometry': {u'location': {u'lat': '60.1866719', u'lng': '24.8254933'}}}, u'gmail.com': {u'geometry': {u'location': {u'lat': 45.79559208545012, u'lng': 2.7429090515033137}}}, u'uni.lu': {u'geometry': {u'location': {u'lat': '49.5042575', u'lng': '5.9461973'}}}, u'ahicf.com': {u'geometry': {u'location': {u'lat': '48.8801743', u'lng': '2.3598598'}}}, u'sib.swiss': {u'geometry': {u'location': {u'lat': '46.1935479', u'lng': '17'}}}, u'infoclio.ch': {u'geometry': {u'location': {u'lat': '46.9464269', u'lng': '7.4360048'}}}}\n"
     ]
    }
   ],
   "source": [
    "##AFTER CORRECTION,READ IT BACK TO COMPlETE PARSING (1stcol=name,second col=lat,long)\n",
    "##PRODUCE LAT/LNG FIELDS AS FOLLOW\n",
    "##'mines.org': {u'geometry': {u'location': {u'lat': 48.845585, u'lng': 2.339632}}}\n",
    "#FOR \"NOTRELEVANT\" fields,so far we will use geocord 45.3896523,-5.4866776,8.25, in the atlantic ocean (gmail accouns and such)\n",
    "#WE will randomly spread it to distinguish from anon accounts.\n",
    "def correct_geolocs_by_hand():\n",
    "    import csv\n",
    "    import random\n",
    "    dict_loc_dicts_to_replace_TO8BE8MANUALLY8EDITED_in_geocoded_locs={}\n",
    "    with open(\"./CSVs_for_manual_fixing/location_refining.csv\", 'rb') as myfile:\n",
    "    \n",
    "    \n",
    "        wr = csv.reader(myfile)\n",
    "        #print wr\n",
    "        for row in wr:\n",
    "                latlngdict= {u'geometry': {u'location': {u'lat': None, u'lng': None}}}\n",
    "         #       print row[0],\"/\",\"(\"+row[1]+\")\"\n",
    "                latrow=re.sub(r'', '',str(row[1]))\n",
    "                sep = \",\"\n",
    "                latrow= latrow.split(sep, 1)[0]\n",
    "          #      print latrow\n",
    "                \n",
    "                if latrow == \"NOTRELEVANT\" :\n",
    "                    #ADD RANDON 0.03 TO NOTRELEVLATLNG\n",
    "                    latlngdict[u'geometry'][u'location'][u'lat']= 45.3896523+random.random()\n",
    "                    latlngdict[u'geometry'][u'location'][u'lng']= 2.339632+random.random()\n",
    "                else:\n",
    "                    \n",
    "                    lngrow=re.sub(r'.*,', '',str(row[1]))\n",
    "                    #sep = \",\"\n",
    "                    #latrow= latrow.split(sep, 1)[0]\n",
    "           #         print lngrow\n",
    "                    latlngdict[u'geometry'][u'location'][u'lat']=latrow\n",
    "                    latlngdict[u'geometry'][u'location'][u'lng']=lngrow\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "            #    print latlngdict\n",
    "                dict_loc_dicts_to_replace_TO8BE8MANUALLY8EDITED_in_geocoded_locs[unicode(row[0])]= latlngdict\n",
    "                \n",
    "\n",
    "    return dict_loc_dicts_to_replace_TO8BE8MANUALLY8EDITED_in_geocoded_locs\n",
    "\n",
    "\n",
    "dict_de_localisations_de_remplacement= correct_geolocs_by_hand()\n",
    "print dict_de_localisations_de_remplacement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_correction_by_dict(dict_to_correct,value_to_find,dict_with_corrections_arranged_by_keys):\n",
    "    dict_corrected=dict.copy(dict_to_correct)\n",
    "    keys = []\n",
    "    \n",
    "    for key in dict_with_corrections_arranged_by_keys:\n",
    "        \n",
    "            #print key\n",
    "            keys.append(unicode(key))\n",
    "    print keys, \"___??_________\"\n",
    "    keystash = keys\n",
    "    for dict_name in dict_to_correct:\n",
    "        \n",
    "        print dict_name,\"!!!???\"\n",
    "        #print dict_to_correct[unicode(dict_name)]\n",
    "        \n",
    "        \n",
    "        #print unicode(dict_to_correct[unicode(dict_name)]),\"----!!----\"\n",
    "        if unicode(dict_name) in keys :\n",
    "                keystash.remove(unicode(dict_name))\n",
    "            #if dict_to_correct[unicode(dict_name)] == value_to_find:\n",
    "                print \"FOUND IT!!!!!!!!!!!!!!!!!!!!!!!\"\n",
    "                dict_corrected[unicode(dict_name)]= dict_with_corrections_arranged_by_keys[key]\n",
    "                print \"DICT CORRIGE\",dict_corrected[unicode(dict_name)]\n",
    "            #else:\n",
    "            #    print \"BIGBUG as match\"\n",
    "            #    break\n",
    "    ###KEYSTASH IS TO ADD MANUALLY REPLACEMENT ADRESSES    \n",
    "    print keystash\n",
    "    if len(keystash) >0:\n",
    "        for keyst in keystash:\n",
    "            dict_corrected[keyst]= dict_with_corrections_arranged_by_keys[keyst]\n",
    "    print dict_corrected\n",
    "    return dict_corrected\n",
    "    \n",
    "\n",
    "dict_corrected_DH= dict_correction_by_dict(geocoded_locs,\"TO8BE8MANUALLY8EDITED\",dict_de_localisations_de_remplacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dict_corrected_DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open('dict_corrected_DH.obj', 'wb') as handle:\n",
    "    pickle.dump(dict_corrected_DH, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dict_corrected_DH.obj', 'rb') as handle:\n",
    "    dict_corrected_DH = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dict_corrected_DH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-e725142f834e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-e725142f834e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def stats_corpus():\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def stats_corpus():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0351086459122\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-29a123259797>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-29a123259797>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "print enchant.list_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyse =topic_analysis_with_nltk_gensim(corpus_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_analysis_with_nltk_gensim(string_to_read):\n",
    "    string_to_read=unicode(str(string_to_read), 'utf8')\n",
    "    lng = language_detection_with_pyenchant(string_to_read)\n",
    "   \n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    import string\n",
    "    print lng\n",
    "    stop = set(stopwords.words(lng))\n",
    "    exclude = set(string.punctuation)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "        \n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "\n",
    "    doc_clean = clean(string_to_read).split()\n",
    "    print \"DOC CLEAN\",doc_clean\n",
    "        # Importing Gensim\n",
    "    import gensim\n",
    "    from gensim import corpora\n",
    "\n",
    "        # Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "    dictionary = corpora.Dictionary([doc_clean])\n",
    "\n",
    "        # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = dictionary.doc2bow(doc_clean)\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    print Lda\n",
    "\n",
    "        # Running and Trainign LDA model on the document term matrix.\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=5)\n",
    "    return ldamodel\n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #return [topic_words,doctopic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
